name: Auto Update Blog

on:
  schedule:
    # í•˜ë£¨ 4íšŒ ì‹¤í–‰ (KST 02:00, 08:00, 14:00, 20:00)
    - cron: '0 17 * * *'  # KST 02:00
    - cron: '0 23 * * *'  # KST 08:00
    - cron: '0 5 * * *'   # KST 14:00
    - cron: '0 11 * * *'  # KST 20:00
  workflow_dispatch:
    inputs:
      skip_crawl:
        description: 'Skip crawling (use existing data)'
        required: false
        default: 'false'

permissions:
  contents: write

env:
  NODE_VERSION: '20'
  PNPM_VERSION: '9'

jobs:
  update-blog:
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install

      # ============================================
      # NEW PIPELINE: Topic-based Content Generation
      # crawl â†’ extract-topics â†’ research-topic â†’ write-article â†’ generate-image
      # ============================================

      # Phase 1: Crawl (All Sources)
      - name: Crawl new posts (DC Inside)
        if: github.event.inputs.skip_crawl != 'true'
        run: pnpm crawl --pages=5
        continue-on-error: true

      - name: Crawl RSS feeds (Official Blogs + News)
        if: github.event.inputs.skip_crawl != 'true'
        run: pnpm crawl-rss
        continue-on-error: true

      # Phase 2: Extract Topics (with retry)
      - name: Extract discussable topics
        id: extract
        run: |
          MAX_RETRIES=3
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if pnpm extract-topics; then
              echo "âœ… Topic extraction completed successfully"
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              echo "âš ï¸ Extract attempt $RETRY_COUNT failed, retrying in 10s..."
              sleep 10
            fi
          done

          TOPIC_COUNT=$(ls -1 data/topics/*.json 2>/dev/null | wc -l)
          echo "topic_count=$TOPIC_COUNT" >> $GITHUB_OUTPUT
          echo "ðŸ“‹ Extracted $TOPIC_COUNT topic(s)"
        env:
          GEMINI_API_KEY: ${{ secrets.GOOGLE_AI_API_KEY }}

      - name: Check for topics
        id: check_topics
        run: |
          if [ -d "data/topics" ] && [ "$(ls -A data/topics 2>/dev/null)" ]; then
            echo "has_topics=true" >> $GITHUB_OUTPUT
          else
            echo "has_topics=false" >> $GITHUB_OUTPUT
          fi

      # Phase 3: Research Topics (with retry)
      - name: Research topics with SearchMode
        if: steps.check_topics.outputs.has_topics == 'true'
        id: research
        run: |
          MAX_RETRIES=3
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if pnpm research-topic; then
              echo "âœ… Research completed successfully"
              PUBLISHABLE=$(ls -1 data/researched/*.json 2>/dev/null | xargs -I {} sh -c 'grep -l "\"canPublish\": true" {}' 2>/dev/null | wc -l)
              echo "publishable_count=$PUBLISHABLE" >> $GITHUB_OUTPUT
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              echo "âš ï¸ Research attempt $RETRY_COUNT failed, retrying in 10s..."
              sleep 10
            fi
          done

          if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then
            echo "âŒ Research failed after $MAX_RETRIES attempts"
            exit 1
          fi
        env:
          GEMINI_API_KEY: ${{ secrets.GOOGLE_AI_API_KEY }}

      # Phase 4: Write Articles
      - name: Write articles from research
        if: steps.check_topics.outputs.has_topics == 'true'
        id: write
        run: |
          MAX_RETRIES=3
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if pnpm write-article; then
              echo "âœ… Article writing completed successfully"
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              echo "âš ï¸ Writing attempt $RETRY_COUNT failed, retrying in 10s..."
              sleep 10
            fi
          done

          if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then
            echo "âŒ Article writing failed after $MAX_RETRIES attempts"
            exit 1
          fi
        env:
          GEMINI_API_KEY: ${{ secrets.GOOGLE_AI_API_KEY }}

      # Phase 5: Generate Images
      - name: Generate cover images
        if: steps.check_topics.outputs.has_topics == 'true'
        id: generate_images
        run: |
          MAX_RETRIES=3
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if pnpm generate-image; then
              echo "âœ… Image generation completed successfully"
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              echo "âš ï¸ Image generation attempt $RETRY_COUNT failed, retrying in 15s..."
              sleep 15
            fi
          done
        env:
          GOOGLE_AI_API_KEY: ${{ secrets.GOOGLE_AI_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GOOGLE_AI_API_KEY }}
          SILICONFLOW_API_KEY: ${{ secrets.SILICONFLOW_API_KEY }}
          ENABLE_IMAGE_GENERATION: 'true'

      # Phase 6: Build & Deploy
      - name: Build website
        id: build
        run: |
          cd apps/web
          pnpm build

      - name: Check for changes
        id: check_changes
        run: |
          git add -A
          if git diff --staged --quiet; then
            echo "has_changes=false" >> $GITHUB_OUTPUT
          else
            echo "has_changes=true" >> $GITHUB_OUTPUT
            echo "ðŸ“Š Changes summary:"
            git diff --staged --stat | tail -5
          fi

      - name: Prepare PR metadata
        id: pr_meta
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          NEW_POSTS=$(git diff --staged --name-only | grep "content/posts/ko" | grep ".mdx" | wc -l)
          NEW_IMAGES=$(git diff --staged --name-only | grep "images/posts" | wc -l)
          echo "new_posts=$NEW_POSTS" >> $GITHUB_OUTPUT
          echo "new_images=$NEW_IMAGES" >> $GITHUB_OUTPUT
          echo "timestamp=$(date +'%Y-%m-%d %H:%M')" >> $GITHUB_OUTPUT

      - name: Commit and push changes
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git commit -m "chore: auto-update blog (+${{ steps.pr_meta.outputs.new_posts }} posts, +${{ steps.pr_meta.outputs.new_images }} images) ${{ steps.pr_meta.outputs.timestamp }}"
          git push

      # Phase 7: Report status
      - name: Report pipeline status
        if: always()
        run: |
          echo "ðŸ“Š Pipeline Summary (New Topic-based Pipeline)"
          echo "=============================================="
          echo "Topics extracted: ${{ steps.extract.outputs.topic_count || '0' }}"
          echo "Publishable: ${{ steps.research.outputs.publishable_count || '0' }}"
          echo "Changes: ${{ steps.check_changes.outputs.has_changes }}"
          echo ""
          echo "ðŸ“ Current stats:"
          echo "- Raw posts: $(ls data/raw/*.json 2>/dev/null | wc -l)"
          echo "- Topics: $(ls data/topics/*.json 2>/dev/null | wc -l)"
          echo "- Researched: $(ls data/researched/*.json 2>/dev/null | wc -l)"
          echo "- Published: $(ls data/published/*.json 2>/dev/null | wc -l)"
          echo "- Posts (ko): $(ls apps/web/content/posts/ko/*.mdx 2>/dev/null | wc -l)"
          echo "- Posts (en): $(ls apps/web/content/posts/en/*.mdx 2>/dev/null | wc -l)"
