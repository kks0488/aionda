{
  "id": "arstechnica-577ch86",
  "sourceId": "arstechnica",
  "sourceName": "Ars Technica",
  "sourceTier": "A",
  "sourceType": "news",
  "title": "ChatGPT falls to new data-pilfering attack as a vicious cycle in AI continues",
  "link": "https://arstechnica.com/security/2026/01/chatgpt-falls-to-new-data-pilfering-attack-as-a-vicious-cycle-in-ai-continues/",
  "pubDate": "Thu, 08 Jan 2026 14:00:07 +0000",
  "contentSnippet": "Will LLMs ever be able to stamp out the root cause of these attacks? Possibly not.",
  "content": "\n                        Will LLMs ever be able to stamp out the root cause of these attacks? Possibly not.\n                    ",
  "categories": [
    "AI",
    "Biz & IT",
    "Security",
    "chatbots",
    "data exfiltration",
    "prompt injections"
  ],
  "fetchedAt": "2026-01-14T01:48:36.299Z"
}