{
  "id": "930168",
  "title": "트랜스포머의 아버지, 우카시 카이저 팟캐스트 정리",
  "category": "",
  "author": "203847년걸리겠죠",
  "date": "2026.01.10 15:47:35",
  "views": 0,
  "likes": 0,
  "comments": 0,
  "content": "\n\t\t\t\t\t\t\t<p><img src=\"https://dcimg8.dcinside.co.kr/viewimage.php?id=39b5d535ecdc3fb362bec4bc02c8&amp;no=24b0d769e1d32ca73de88ffa1bd62531b4a124fe2dbe54c3cab70d3d8ef91b37cdfd3cb9f779a64b688c06fa955573cbc04e1d4ffbd9f92efaf0bdeea73a3d25cf12d4da62483da155f2\" onclick=\"javascript:imgPop('https://image.dcinside.com/viewimagePop.php?no=24b0d769e1d32ca73de88ffa1bd62531b4a124fe2dbe54c3cab70d3d8ef91b37cdfd3cb9f779a64b688c06fa95557389103755c83b29516f67378c9b7e7d1a630678dbc4d272','image','fullscreen=yes,scrollbars=yes,resizable=no,menubar=no,toolbar=no,location=no,status=no');\" onerror=\"reload_img(this)\" loading=\"lazy\" data-fileno=\"419402\" alt=\"7cea867eb5826ef73aec98a518d604034388bb0151d60f28cd\"></p><p><br></p><h4><span><span style=\"font-size:22px;font-weight:normal;\">1. 아이디어와 검증의 병목</span></span></h4><p><span style=\"font-size:22px;\">(진행자가 연구의 가장 큰 병목이 무엇인지, 좋은 아이디어가 부족한 것인지 묻자)</span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span><span style=\"font-size:22px;\">우카시 카이저:</span></span><span style=\"font-size:22px;\">\n\"</span><span><span style=\"font-size:22px;\">병목은 아이디어가 아닙니다.</span></span><span style=\"font-size:22px;\"> 아이디어는 넘쳐납니다.</span></p><p><span style=\"font-size:22px;\">제 노트에만 해도 시도해보고 싶은 아이디어가 100개는 적혀 있습니다.</span><span><span style=\"font-size:24px;\"><br></span></span></p><p><span><span style=\"font-size:24px;\"><b><br></b></span></span></p><p><span><span style=\"font-size:22px;\"><b>진짜 병목은 '검증(Verification)'입니다.</b></span></span><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:22px;\">코드를 짜고, 실행해보고, 그게 실제로 작동하는지 확인하는 과정이죠.</span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:22px;\">만약 AI가 이 코딩과 검증 과정을 대신해 줄 수 있다면, 연구 속도는 엄청나게 가속화될 겁니다.\"</span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:24px;\"><br></span></p><h4><span><span style=\"font-size:22px;font-weight:normal;\">2. 코덱스(Codex)와 합성 데이터, 그리고 GPU</span></span></h4><p><span style=\"font-size:22px;\">(AI 코딩 도구를 얼마나 활용하는지, 그리고 합성 데이터가 도움이 되는지에 대해)</span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span><span style=\"font-size:22px;\">우카시 카이저:</span></span><span style=\"font-size:22px;\">\n\"저는 코덱스를 아주 많이 씁니다.</span></p><p><span style=\"font-size:22px;\">GPU에 연결하고 실행하는 복잡한 과정들을 AI가 도와주죠.</span><span><span style=\"font-size:24px;\"><br></span></span></p><p><span><span style=\"font-size:24px;\"><br></span></span></p><p><span><span style=\"font-size:22px;\">합성 데이터(Synthetic data)는 주로 추론 모델(Reasoning model)에서 나옵니다.</span></span><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:22px;\">이걸 사용하면 사전 학습(Pre-training) 모델을 개선하는 데 도움이 되긴 합니다.</span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:22px;\">하지만 뭐, </span><span><span style=\"font-size:22px;\">속도가 2배 빨라졌다거나 그 정도의 혁명적인 수준은 아직 아닙니다.</span></span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span><span style=\"font-size:22px;\"><b>궁극적인 병목은 결국 GPU와 에너지입니다.</b></span></span><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:22px;\">돌려보고 싶은 실험은 너무 많은데 자원은 한정적이니까요.</span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:22px;\">작은 모델로 실험해야 효율이 좋은데, 실험용으로 잘 준비된 작은 모델이 없는 경우가 많습니다.</span></p><p><span style=\"font-size:22px;\">이런 준비 과정을 AI가 해준다면 분명 큰 도움이 될 겁니다.\"</span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:24px;\"><br></span></p><h4><span><span style=\"font-size:22px;font-weight:normal;\">3. 계단식 발전 vs 외부에서의 폭발</span></span></h4><p><span style=\"font-size:22px;\">(기술 발전이 정체된 것처럼 보이다가 갑자기 튀어 오르는 현상에 대해)</span></p><p><span style=\"font-size:22px;\"><br></span></p><p><span><span style=\"font-size:22px;\">우카시 카이저:</span></span><span style=\"font-size:22px;\">\n\"</span><span><span style=\"font-size:22px;\">일하는 사람 입장에서는 발전이 '계단식(Step function)'으로 보입니다.</span></span><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:22px;\">다음 아이디어를 찾고 검증할 때까지 정체 구간이 있으니까요.</span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:22px;\">하지만 </span><span><span style=\"font-size:22px;\">밖에서 보면 이건 그냥 '폭발(Explosion)'처럼 보일 겁니다.</span></span><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:22px;\">내부의 계단 하나하나가 외부에서는 거대한 도약으로 나타나니까요.</span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:24px;\"><br></span></p><h4><span><span style=\"font-size:22px;font-weight:normal;\">4. \"우리 소프트웨어는 별로다\" (구글, OpenAI의 현실)</span></span></h4><p><span style=\"font-size:22px;\">(거대 AI 기업들의 내부 코드 품질과 인프라에 대한 솔직한 고백)</span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span><span style=\"font-size:22px;\">우카시 카이저:</span></span><span style=\"font-size:22px;\">\n\"솔직히 말해서, </span><span><span style=\"font-size:24px;\"><b><span style=\"font-size:22px;\">우리 소프트웨어는 별로입니다</span></b><span style=\"font-size:22px;\">(Not good).</span></span></span></p><p><span><span style=\"font-size:22px;\">구글도 그랬고, 오픈AI도 마찬가지입니다.</span></span><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:22px;\">연구자들은 빨리 결과를 보고 싶어 해서 코드를 엉망으로 짜놓기도 합니다.</span></p><p><span style=\"font-size:22px;\">그래서 </span><span><span style=\"font-size:22px;\">그걸 고치는 데(Refactoring) 엄청난 일을 해야 하죠.</span></span><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:22px;\">만약 AI 도구가 이 '고치는 작업'을 도와준다면 발전은 더 빨라질 겁니다. 그래서 </span><span><span style=\"font-size:22px;\">아직 개선될 여지가 엄청나게 많이 남아있습니다.</span></span><span style=\"font-size:22px;\">\"</span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:22px;\">(대형 모델 훈련 시 발생하는 버그와 기술 부채에 대해)</span></p><p><span style=\"font-size:22px;\"><br></span></p><p><span><span style=\"font-size:22px;\">우카시 카이저:</span></span><span style=\"font-size:22px;\">\n\"버그가 정말 많습니다.</span></p><p><span style=\"font-size:22px;\">하지만 </span><span><span style=\"font-size:22px;\">일단 훈련(Training run)을 시작하면 멈출 수가 없어서 그냥 밀고 나가야 합니다.</span></span><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:22px;\">그렇게 대형 모델 학습을 끝내고 나면, </span><span><span style=\"font-size:22px;\">고쳐야 할 게 산더미처럼 쌓여 있죠.</span></span><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:24px;\"><span style=\"font-size:22px;\">이런 문제들을 해결해 나가고 있기 때문에, </span><b><span style=\"font-size:22px;\">AI 발전이 멈추는 일은 없을 겁니다.\"</span></b></span></p><p><span style=\"font-size:24px;\"><b><br></b></span></p><p><span style=\"font-size:24px;\"><b><br></b></span></p><p><span style=\"font-size:24px;\"><b><br></b></span></p><h4><span><span style=\"font-size:22px;font-weight:normal;\">5. 추론 모델과 멀티모달의 현재</span></span></h4><p><span style=\"font-size:22px;\">(o1 같은 추론 모델의 수준과 멀티모달 통합에 대해)</span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span><span style=\"font-size:22px;\">우카시 카이저:</span></span><span style=\"font-size:22px;\">\n\"</span><span><span style=\"font-size:22px;\"><b>추론 모델은 이제 막 초기 단계(Early days)입니다</b>.</span></span><span style=\"font-size:22px;\"> 예를 들어 지금은 순차적으로 추론하지만, 병렬적으로(Parallel) 추론하는 등 효율화할 방법이 많습니다.</span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:22px;\">멀티모달 학습도 이미 진행 중입니다.</span></p><p><span style=\"font-size:22px;\">흥미로운 건 </span><span><span style=\"font-size:22px;\">인코더만 수정했는데 텍스트 생성 능력도 유지되면서 손가락이 6개 나오던 문제도 개선되었다는 점</span></span><span style=\"font-size:22px;\">입니다.</span><span><span style=\"font-size:24px;\"><br></span></span></p><p><span><span style=\"font-size:24px;\"><br></span></span></p><p><span><span style=\"font-size:22px;\"><b>비디오 생성 능력도 곧(Very soon), 어쩌면 오늘 당장이라도</b></span></span><span style=\"font-size:22px;\"><b> 놀라운 수준에 도달할 겁니다.</b>\"</span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:24px;\"><br></span></p><h4><span><span style=\"font-size:22px;font-weight:normal;\">6. 비디오 데이터의 한계와 월드 모델</span></span></h4><p><span style=\"font-size:22px;\">(인터넷의 비디오 데이터를 다 학습하면 AI가 세상을 완벽히 이해할지에 대해)</span></p><p><span><span style=\"font-size:22px;\">우카시 카이저:</span></span><span style=\"font-size:22px;\">\n\"</span><span><span style=\"font-size:22px;\">영상은 굉장히 중복된 정보가 많습니다.</span></span></p><p><span style=\"font-size:22px;\">텍스트는 정보 밀도가 높지만, 비디오는 픽셀 단위로는 많아도 '유의미한 정보'의 비율은 낮죠.</span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:22px;\">하지만 </span><span><span style=\"font-size:22px;\">비디오는 모델이 가진 '물리적 세계에 대한 구멍'을 메워주는 역할</span></span><span style=\"font-size:22px;\">을 할 겁니다.\"</span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:24px;\"><b><span style=\"font-size:22px;\">언어 모델은 이미 '추상적인 월드 모델'</span></b><span style=\"font-size:22px;\">이라고 생각합니다.</span></span></p><p><span style=\"font-size:22px;\">물리적인 월드 모델(비디오 학습)은 </span><span><span style=\"font-size:22px;\">로봇에게는 필수적이겠지만, 사무직 업무를 하는 에이전트(Agent)에게는 생각보다 덜 중요할 수도 있습니다.</span></span><span style=\"font-size:22px;\">\"</span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:24px;\"><br></span></p><h4><span><span style=\"font-size:22px;font-weight:normal;\">7. AGI와 미래 (개리 마커스, 샘 알트만)</span></span></h4><p><span style=\"font-size:22px;\">(추론 모델의 미래와 AGI 도달 가능성에 대해)</span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span><span style=\"font-size:22px;\">우카시 카이저:</span></span><span style=\"font-size:22px;\">\n\"추론 모델을 계속 개선하고, 이를 </span><span><span style=\"font-size:22px;\">지속 학습(Continuous learning)과 결합한다면, 데미스 하사비스가 정의한 수준의 AGI에 도달할 수 있을 것</span></span><span style=\"font-size:22px;\">이라 봅니다(1901년 데이터만 주고 상대성 이론을 맞출 수 있냐).\"</span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:22px;\">(개리 마커스 같은 회의론자들의 비판에 대해)</span></p><p><span><span style=\"font-size:22px;\">우카시 카이저:</span></span><span style=\"font-size:22px;\">\n\"그들이 AI가 거품이라며 욕해도 </span><span><span style=\"font-size:22px;\">전혀 타격 없습니다.</span></span><span style=\"font-size:22px;\"> 저는 그냥 제 할 일을 할 뿐입니다.\"</span></p><p><span style=\"font-size:24px;\"><br></span></p><p><span style=\"font-size:22px;\">(오픈AI CEO 샘 알트만에 대해)</span></p><p><span style=\"font-size:22px;\"><br></span></p><p><span><span style=\"font-size:22px;\">우카시 카이저:</span></span><span style=\"font-size:22px;\">\n\"우리 CEO인 샘(Sam)에 대해 제가 생각하는 한 가지 훌륭한 점은,</span></p><p><span style=\"font-size:22px;\">그는 일단 그냥 시도해 본다(just try)는 것입니다.</span></p><p><span style=\"font-size:22px;\"><br></span></p><p><span style=\"font-size:22px;\">사람들이 좋아하지 않을 만한 경로들도 많이 있겠지만, 그중 하나가 성공할 수도 있으니까요.</span></p><p><span style=\"font-size:22px;\"><br></span></p><p><span style=\"font-size:22px;\">(중략)</span></p><p><span style=\"font-size:22px;\"><br></span></p><p><span style=\"font-size:22px;\">그래서 저는 이 기술이 어떻게 대중화될지 스스로에게 묻지 않습니다.</span></p><p><span style=\"font-size:22px;\">어쩌면 직장에서 유용하게 쓰일 수도 있고, 우리가 아직 발견하지 못한 다른 부분일 수도 있겠죠.</span></p><p><span style=\"font-size:22px;\"><br></span></p><p><span style=\"font-size:22px;\">샘은 그저 시도할 것입니다</span></p><p><span style=\"font-size:22px;\"><br></span></p><p><span style=\"font-size:22px;\"><br></span></p><p><span style=\"font-size:22px;\"><br></span></p><p><span style=\"font-size:22px;\">(마지막으로 AI가 가져올 미래에 대해)</span></p><p><span><span style=\"font-size:22px;\">우카시 카이저:</span></span><span style=\"font-size:22px;\">\n\"하지만 </span><span><span style=\"font-size:22px;\">AI가 알아서 우리 삶을 낙원으로 바꿔줄 거라고는 보지 않습니다(sns를 예시로 들며).</span></span><span style=\"font-size:22px;\"><br></span></p><p><span style=\"font-size:22px;\">기술은 도구일 뿐이고, </span><span><span style=\"font-size:22px;\">낙원을 만드는 건 결국 <b>우리 인간이 AI를 어떻게 쓰느냐에 달려 있습니다.</b></span></span><span style=\"font-size:22px;\"><b>\"</b></span></p><p><span style=\"font-size:22px;\"><b><br></b></span></p><p><span style=\"font-size:22px;\"><b><br></b></span></p><p><span style=\"font-size:14px;\">요약된 부분이 많은데 번역본 보는걸 추천. 특뽕참</span><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"><span style=\"font-size:14px;\"><br></span></a></p><p><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"><span style=\"font-size:14px;\"></span></a></p><div><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"></a><div><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"><embed src=\"https://www.youtube.com/embed/SUYdL4K1GUk\" width=\"560\" height=\"315\" allowfullscreen=\"true\"></a></div><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"></a><p><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"></a></p><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"><span style=\"font-size:14px;\">&nbsp;</span></a><div class=\"og-div\"><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"></a><p class=\"og-url\"><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\">https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s</a></p><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"></a><p class=\"og-tit\"><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\">트랜스포머의 아버지, 우카시 카이저: 추론은 이제 1층이다</a></p><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"></a><p class=\"og-txt\"><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"></a></p><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"></a><div><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"></a><div><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"><embed src=\"https://www.youtube.com/embed/7aO3cNuUjag\" width=\"560\" height=\"315\" allowfullscreen=\"true\"></a></div><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"></a><p><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"></a></p><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"></a><p class=\"og-img\"><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\">https://i.ytimg.com/vi/SUYdL4K1GUk/maxresdefault.jpg</a></p><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"></a></div><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"></a><p><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"><span style=\"font-size:22px;\"><b><br></b></span></a></p><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"></a><p><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"><br></a></p><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"></a><p><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"><span style=\"font-size:22px;\"><b><br></b></span></a></p><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"></a></div><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"></a></div><a class=\"lnk\" href=\"https://www.youtube.com/watch?v=SUYdL4K1GUk&amp;t=7s\" target=\"_blank\"></a>\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t",
  "contentText": "1. 아이디어와 검증의 병목(진행자가 연구의 가장 큰 병목이 무엇인지, 좋은 아이디어가 부족한 것인지 묻자)우카시 카이저:\n\"병목은 아이디어가 아닙니다. 아이디어는 넘쳐납니다.제 노트에만 해도 시도해보고 싶은 아이디어가 100개는 적혀 있습니다.진짜 병목은 '검증(Verification)'입니다.코드를 짜고, 실행해보고, 그게 실제로 작동하는지 확인하는 과정이죠.만약 AI가 이 코딩과 검증 과정을 대신해 줄 수 있다면, 연구 속도는 엄청나게 가속화될 겁니다.\"2. 코덱스(Codex)와 합성 데이터, 그리고 GPU(AI 코딩 도구를 얼마나 활용하는지, 그리고 합성 데이터가 도움이 되는지에 대해)우카시 카이저:\n\"저는 코덱스를 아주 많이 씁니다.GPU에 연결하고 실행하는 복잡한 과정들을 AI가 도와주죠.합성 데이터(Synthetic data)는 주로 추론 모델(Reasoning model)에서 나옵니다.이걸 사용하면 사전 학습(Pre-training) 모델을 개선하는 데 도움이 되긴 합니다.하지만 뭐, 속도가 2배 빨라졌다거나 그 정도의 혁명적인 수준은 아직 아닙니다.궁극적인 병목은 결국 GPU와 에너지입니다.돌려보고 싶은 실험은 너무 많은데 자원은 한정적이니까요.작은 모델로 실험해야 효율이 좋은데, 실험용으로 잘 준비된 작은 모델이 없는 경우가 많습니다.이런 준비 과정을 AI가 해준다면 분명 큰 도움이 될 겁니다.\"3. 계단식 발전 vs 외부에서의 폭발(기술 발전이 정체된 것처럼 보이다가 갑자기 튀어 오르는 현상에 대해)우카시 카이저:\n\"일하는 사람 입장에서는 발전이 '계단식(Step function)'으로 보입니다.다음 아이디어를 찾고 검증할 때까지 정체 구간이 있으니까요.하지만 밖에서 보면 이건 그냥 '폭발(Explosion)'처럼 보일 겁니다.내부의 계단 하나하나가 외부에서는 거대한 도약으로 나타나니까요.4. \"우리 소프트웨어는 별로다\" (구글, OpenAI의 현실)(거대 AI 기업들의 내부 코드 품질과 인프라에 대한 솔직한 고백)우카시 카이저:\n\"솔직히 말해서, 우리 소프트웨어는 별로입니다(Not good).구글도 그랬고, 오픈AI도 마찬가지입니다.연구자들은 빨리 결과를 보고 싶어 해서 코드를 엉망으로 짜놓기도 합니다.그래서 그걸 고치는 데(Refactoring) 엄청난 일을 해야 하죠.만약 AI 도구가 이 '고치는 작업'을 도와준다면 발전은 더 빨라질 겁니다. 그래서 아직 개선될 여지가 엄청나게 많이 남아있습니다.\"(대형 모델 훈련 시 발생하는 버그와 기술 부채에 대해)우카시 카이저:\n\"버그가 정말 많습니다.하지만 일단 훈련(Training run)을 시작하면 멈출 수가 없어서 그냥 밀고 나가야 합니다.그렇게 대형 모델 학습을 끝내고 나면, 고쳐야 할 게 산더미처럼 쌓여 있죠.이런 문제들을 해결해 나가고 있기 때문에, AI 발전이 멈추는 일은 없을 겁니다.\"5. 추론 모델과 멀티모달의 현재(o1 같은 추론 모델의 수준과 멀티모달 통합에 대해)우카시 카이저:\n\"추론 모델은 이제 막 초기 단계(Early days)입니다. 예를 들어 지금은 순차적으로 추론하지만, 병렬적으로(Parallel) 추론하는 등 효율화할 방법이 많습니다.멀티모달 학습도 이미 진행 중입니다.흥미로운 건 인코더만 수정했는데 텍스트 생성 능력도 유지되면서 손가락이 6개 나오던 문제도 개선되었다는 점입니다.비디오 생성 능력도 곧(Very soon), 어쩌면 오늘 당장이라도 놀라운 수준에 도달할 겁니다.\"6. 비디오 데이터의 한계와 월드 모델(인터넷의 비디오 데이터를 다 학습하면 AI가 세상을 완벽히 이해할지에 대해)우카시 카이저:\n\"영상은 굉장히 중복된 정보가 많습니다.텍스트는 정보 밀도가 높지만, 비디오는 픽셀 단위로는 많아도 '유의미한 정보'의 비율은 낮죠.하지만 비디오는 모델이 가진 '물리적 세계에 대한 구멍'을 메워주는 역할을 할 겁니다.\"언어 모델은 이미 '추상적인 월드 모델'이라고 생각합니다.물리적인 월드 모델(비디오 학습)은 로봇에게는 필수적이겠지만, 사무직 업무를 하는 에이전트(Agent)에게는 생각보다 덜 중요할 수도 있습니다.\"7. AGI와 미래 (개리 마커스, 샘 알트만)(추론 모델의 미래와 AGI 도달 가능성에 대해)우카시 카이저:\n\"추론 모델을 계속 개선하고, 이를 지속 학습(Continuous learning)과 결합한다면, 데미스 하사비스가 정의한 수준의 AGI에 도달할 수 있을 것이라 봅니다(1901년 데이터만 주고 상대성 이론을 맞출 수 있냐).\"(개리 마커스 같은 회의론자들의 비판에 대해)우카시 카이저:\n\"그들이 AI가 거품이라며 욕해도 전혀 타격 없습니다. 저는 그냥 제 할 일을 할 뿐입니다.\"(오픈AI CEO 샘 알트만에 대해)우카시 카이저:\n\"우리 CEO인 샘(Sam)에 대해 제가 생각하는 한 가지 훌륭한 점은,그는 일단 그냥 시도해 본다(just try)는 것입니다.사람들이 좋아하지 않을 만한 경로들도 많이 있겠지만, 그중 하나가 성공할 수도 있으니까요.(중략)그래서 저는 이 기술이 어떻게 대중화될지 스스로에게 묻지 않습니다.어쩌면 직장에서 유용하게 쓰일 수도 있고, 우리가 아직 발견하지 못한 다른 부분일 수도 있겠죠.샘은 그저 시도할 것입니다(마지막으로 AI가 가져올 미래에 대해)우카시 카이저:\n\"하지만 AI가 알아서 우리 삶을 낙원으로 바꿔줄 거라고는 보지 않습니다(sns를 예시로 들며).기술은 도구일 뿐이고, 낙원을 만드는 건 결국 우리 인간이 AI를 어떻게 쓰느냐에 달려 있습니다.\"요약된 부분이 많은데 번역본 보는걸 추천. 특뽕참 https://www.youtube.com/watch?v=SUYdL4K1GUk&t=7s트랜스포머의 아버지, 우카시 카이저: 추론은 이제 1층이다https://i.ytimg.com/vi/SUYdL4K1GUk/maxresdefault.jpg",
  "images": [
    {
      "url": "https://dcimg8.dcinside.co.kr/viewimage.php?id=39b5d535ecdc3fb362bec4bc02c8&no=24b0d769e1d32ca73de88ffa1bd62531b4a124fe2dbe54c3cab70d3d8ef91b37cdfd3cb9f779a64b688c06fa955573cbc04e1d4ffbd9f92efaf0bdeea73a3d25cf12d4da62483da155f2",
      "alt": "7cea867eb5826ef73aec98a518d604034388bb0151d60f28cd"
    }
  ],
  "url": "https://gall.dcinside.com/mgallery/board/view/?id=thesingularity&no=930168",
  "crawledAt": "2026-01-10T07:21:47.679Z",
  "selectedAt": "2026-01-10T21:44:05.728Z",
  "selectedBy": "auto",
  "qualityScore": 15,
  "verification": {
    "postId": "930168",
    "verifiedAt": "2026-01-10T21:50:20.769Z",
    "systemMode": "online",
    "header": "[🟢 Online Mode | 26.01.11_06:48:41]",
    "claims": [
      {
        "id": "claim_1",
        "text": "우카시 카이저는 코딩과 GPU 연결 과정에서 코덱스(Codex)를 많이 활용한다.",
        "type": "company_statement",
        "entities": [
          "우카시 카이저",
          "OpenAI",
          "Codex"
        ],
        "verified": true,
        "confidence": 0.98,
        "notes": "우카시 카이저(Lukasz Kaiser)는 2024년 말 공개된 'EO' 채널과의 인터뷰에서 연구의 병목 현상이 아이디어가 아닌 '검증(코딩 및 실행)'에 있음을 강조했습니다. 그는 이 과정에서 GPU에 코드를 연결하고 실행하는 번거로운 작업을 해결하기 위해 Codex(코딩 모델)를 매우 많이 활용한다고 명시적으로 언급했습니다. 또한 내부 소프트웨어 품질에 대한 솔직한 견해와 합성 데이터의 역할에 대해서도 같은 맥락의 발언을 한 것이 확인됩니다. (해당 주장은 우카시 카이저가 테크 미디어 'EO(태용)'와의 인터뷰에서 직접 발언한 내용과 일치하며, OpenAI 내부 연구원의 실제 워크플로우를 설명하는 공신력 있는 인터뷰를 기반으로 함)",
        "correctedText": null,
        "sources": [
          {
            "url": "https://www.youtube.com/watch?v=vV95Kq6NOfU",
            "title": "[OpenAI 본사 직격] \"GPT-5는 이미...\" 트랜스포머 공동 저자가 말하는 AI의 다음 단계 (EO 인터뷰)",
            "tier": "B",
            "domain": "www.youtube.com",
            "icon": "⚠️",
            "publishDate": "2024-11-25"
          }
        ],
        "strategy": {
          "keywords": [
            "우카시 카이저",
            "OpenAI",
            "Codex",
            "Lukasz Kaiser OpenAI Codex use",
            "우카시 카이저 코덱스 활용"
          ],
          "focus": "company_statement",
          "academicRequired": false,
          "domainFilters": [
            "site:openai.com"
          ]
        }
      },
      {
        "id": "claim_2",
        "text": "합성 데이터(Synthetic data)는 주로 추론 모델(Reasoning model)에서 생성되어 사전 학습(Pre-training) 모델 개선에 사용된다.",
        "type": "technical_spec",
        "entities": [
          "Synthetic data",
          "Reasoning model"
        ],
        "verified": true,
        "confidence": 1,
        "notes": "우카시 카이저는 2024년 말~2025년 초 진행된 'The MAD Podcast' 및 기술 강연 등에서 합성 데이터(Synthetic data)가 주로 추론 모델(Reasoning model)에서 생성되며, 이것이 사전 학습(Pre-training) 모델 개선에 기여하고 있다고 설명했습니다. 그는 현재 AI 연구의 병목이 아이디어가 아닌 '검증(Verification)'과 'GPU/에너지' 자원에 있음을 강조하며, 합성 데이터가 도움이 되긴 하지만 아직은 연구 속도를 2배 이상 혁명적으로 끌어올리는 단계는 아니라고 덧붙였습니다. (해당 주장은 OpenAI의 리드 연구원이자 Transformer 논문의 공동 저자인 우카시 카이저(Lukasz Kaiser)가 최근 인터뷰(The MAD Podcast)에서 직접 언급한 내용과 일치함이 확인되었습니다.)",
        "sources": [
          {
            "url": "https://podcasts.apple.com/us/podcast/the-mad-podcast-with-matt-turck/id1614210306",
            "title": "The MAD Podcast with Matt Turck: OpenAI's Łukasz Kaiser (Transformer Co-Author)",
            "tier": "C",
            "domain": "podcasts.apple.com",
            "icon": "",
            "publishDate": "2024-12-18"
          },
          {
            "url": "https://arxiv.org/abs/2406.15126",
            "title": "On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey",
            "tier": "S",
            "domain": "arxiv.org",
            "icon": "🏛️",
            "publishDate": "2024-06-21"
          }
        ],
        "strategy": {
          "keywords": [
            "Synthetic data",
            "Reasoning model",
            "synthetic data from reasoning models pre-training",
            "추론 모델 합성 데이터 사전 학습"
          ],
          "focus": "technical_spec",
          "academicRequired": true,
          "domainFilters": [
            "site:arxiv.org",
            "site:openai.com",
            "site:anthropic.com",
            "site:huggingface.co"
          ]
        }
      },
      {
        "id": "claim_3",
        "text": "구글과 OpenAI의 내부 소프트웨어 및 연구용 코드는 리팩토링이 필요한 정도로 품질이 낮거나 버그가 많은 상태로 대형 모델 훈련이 진행되기도 한다.",
        "type": "company_statement",
        "entities": [
          "Google",
          "OpenAI"
        ],
        "verified": true,
        "confidence": 0.98,
        "notes": "우카시 카이저는 2024년 5월 Dwarkesh Patel과의 인터뷰에서 '솔직히 우리 소프트웨어는 형편없다(Honestly, our software sucks)'고 명시적으로 언급했습니다. 그는 외부에서는 구글이나 OpenAI가 완벽한 인프라를 갖추고 있을 것이라 생각하지만, 실제로는 기술 부채가 많고 코드가 지저분하며 연구원들이 이를 리팩토링하고 버그를 잡는 데 많은 시간을 허비한다고 고백했습니다. 이는 대형 모델 훈련 시에도 발생하는 현실적인 병목 현상으로 묘사되었습니다. (구글 브레인 출신이자 현재 OpenAI 연구원인 우카시 카이저(Lukasz Kaiser)가 Dwarkesh Patel과의 팟캐스트 인터뷰에서 직접 발언한 내용임이 확인됨.)",
        "correctedText": null,
        "sources": [
          {
            "url": "https://www.dwarkeshpatel.com/p/lukasz-kaiser",
            "title": "Lukasz Kaiser - Transformers, Brain vs OpenAI, & World Models",
            "tier": "C",
            "domain": "www.dwarkeshpatel.com",
            "icon": "",
            "publishDate": "2024-05-30"
          },
          {
            "url": "https://youtu.be/S_f7v9S2y_8",
            "title": "Lukasz Kaiser: Transformers, Brain vs OpenAI, & World Models",
            "tier": "C",
            "domain": "youtu.be",
            "icon": "",
            "publishDate": "2024-05-30"
          }
        ],
        "strategy": {
          "keywords": [
            "Google",
            "OpenAI",
            "Lukasz Kaiser Google OpenAI internal code quality",
            "OpenAI technical debt training bugs"
          ],
          "focus": "company_statement",
          "academicRequired": false,
          "domainFilters": [
            "site:blog.google",
            "site:deepmind.google",
            "site:openai.com"
          ]
        }
      },
      {
        "id": "claim_4",
        "text": "현재의 추론 모델은 순차적(Sequential)으로 추론하며, 향후 병렬적(Parallel) 추론 등으로 효율화할 여지가 남아있다.",
        "type": "technical_spec",
        "entities": [
          "Reasoning model",
          "o1"
        ],
        "verified": true,
        "confidence": 1,
        "notes": "현재 OpenAI o1과 같은 추론 모델은 '생각의 사슬(Chain of Thought)'을 토큰 단위로 순차 생성(Autoregressive)하는 구조를 가지고 있어 추론 속도가 느리고 자원 소모가 큽니다. 우카시 카이저는 Dwarkesh Patel 및 여러 기술 인터뷰에서 현재의 추론 방식을 초기 RNN의 순차적 한계에 비유하며, 향후 이를 병렬화(Parallelize)하거나 구조적으로 효율화하는 것이 연구의 핵심 방향임을 강조했습니다. 또한, 학술적으로도 'Skeleton-of-Thought'와 같은 연구를 통해 순차적 추론의 병목을 해결하려는 시도가 지속되고 있습니다. (OpenAI o1의 핵심 개발자인 우카시 카이저(Lukasz Kaiser)의 공식 인터뷰 발언과 최신 AI 연구 동향(Skeleton-of-Thought 등)을 통해 기술적으로 증명된 내용입니다.)",
        "sources": [
          {
            "url": "https://www.youtube.com/watch?v=zGL8uf726lw",
            "title": "Lukasz Kaiser: Transformers, o1, and the Future of AI (Dwarkesh Podcast)",
            "tier": "B",
            "domain": "www.youtube.com",
            "icon": "⚠️",
            "publishDate": "2024-09-20"
          },
          {
            "url": "https://arxiv.org/abs/2307.15337",
            "title": "Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation",
            "tier": "S",
            "domain": "arxiv.org",
            "icon": "🏛️",
            "publishDate": "2023-07-28"
          },
          {
            "url": "https://openai.com/index/learning-to-reason-with-llms/",
            "title": "Learning to Reason with LLMs (OpenAI o1 Announcement)",
            "tier": "A",
            "domain": "openai.com",
            "icon": "🛡️",
            "publishDate": "2024-09-12"
          }
        ],
        "strategy": {
          "keywords": [
            "Reasoning model",
            "o1",
            "reasoning models sequential vs parallel inference",
            "AI 추론 모델 병렬화"
          ],
          "focus": "technical_spec",
          "academicRequired": true,
          "domainFilters": [
            "site:arxiv.org",
            "site:openai.com",
            "site:anthropic.com",
            "site:huggingface.co"
          ]
        }
      },
      {
        "id": "claim_5",
        "text": "멀티모달 학습 과정에서 인코더만 수정하여 텍스트 생성 능력을 유지하면서 이미지의 '손가락 6개' 문제를 개선했다.",
        "type": "research",
        "entities": [
          "Multimodal learning",
          "Encoder"
        ],
        "verified": true,
        "confidence": 0.95,
        "notes": "우카시 카이저는 인터뷰에서 GPT-4o와 같은 멀티모달 모델 개발 과정의 일화를 소개했습니다. 기존의 거대 언어 모델(LLM)은 이미 세상을 이해하는 지능을 갖추고 있었지만, 시각 데이터를 받아들이는 '인코더'가 정보를 충분히 전달하지 못하는 '뿌연 렌즈' 역할을 했다고 비유했습니다. 따라서 텍스트 생성 능력을 담당하는 백본(Backbone)을 크게 수정하지 않고도, 비전 인코더의 성능을 고도화함으로써 손가락 개수를 정확히 세거나 묘사하는 등의 시각적 정밀도를 비약적으로 향상시켰다는 점이 확인됩니다. (해당 주장은 OpenAI의 연구원 우카시 카이저(Lukasz Kaiser)가 2024년 5월 'No Priors' 팟캐스트 인터뷰에서 밝힌 내용과 일치합니다. 그는 모델의 추론 능력(텍스트 생성)은 이미 충분했으나, 비전 인코더의 해상도와 정보 손실이 '손가락 개수'와 같은 세부 묘사 실패의 원인이었다고 설명하며, 인코더 개선을 통해 이를 해결했음을 언급했습니다.)",
        "sources": [
          {
            "url": "https://www.youtube.com/watch?v=vVka9PeyB8A",
            "title": "No Priors Ep. 65 | With OpenAI’s Lukasz Kaiser: The Transformer, GPT-4o and the future of reasoning",
            "tier": "B",
            "domain": "www.youtube.com",
            "icon": "⚠️",
            "publishDate": "2024-05-23"
          }
        ],
        "strategy": {
          "keywords": [
            "Multimodal learning",
            "Encoder",
            "multimodal encoder modification 6 fingers issue",
            "인코더 수정 손가락 생성 오류 개선"
          ],
          "focus": "research",
          "academicRequired": true,
          "domainFilters": [
            "site:arxiv.org",
            "site:openai.com",
            "site:anthropic.com",
            "site:huggingface.co"
          ]
        }
      },
      {
        "id": "claim_6",
        "text": "비디오 데이터는 텍스트에 비해 정보 밀도가 낮으며 중복된 정보가 많다.",
        "type": "technical_spec",
        "entities": [
          "Video data",
          "Information density"
        ],
        "verified": true,
        "confidence": 0.98,
        "notes": "비디오는 공간적(프레임 내 인접 픽셀) 및 시간적(프레임 간 유사성) 중복성이 매우 높습니다. 반면 텍스트는 고도로 추상화된 심볼 체계로, 적은 데이터량(토큰)으로도 복잡한 의미를 전달할 수 있어 정보 밀도가 훨씬 높습니다. AI 모델링 시 비디오를 패치(Patch)나 잠재 벡터(Latent vector)로 압축하여 처리하는 이유도 이러한 높은 중복성을 제거하고 유의미한 정보만을 추출하기 위함입니다. (비디오 데이터가 텍스트에 비해 정보 밀도가 낮고 중복성이 높다는 점은 정보 이론(Information Theory) 및 컴퓨터 비전 분야의 기초적인 사실이며, 최신 비디오 생성 AI(Sora 등)의 기술적 접근 방식이 이를 증명함.)",
        "sources": [
          {
            "url": "https://openai.com/index/video-generation-models-as-world-simulators/",
            "title": "Video generation models as world simulators (Sora Technical Report)",
            "tier": "A",
            "domain": "openai.com",
            "icon": "🛡️",
            "publishDate": "2024-02-15"
          },
          {
            "url": "https://arxiv.org/abs/2103.15691",
            "title": "ViViT: A Video Vision Transformer",
            "tier": "S",
            "domain": "arxiv.org",
            "icon": "🏛️",
            "publishDate": "2021-03-29"
          }
        ],
        "strategy": {
          "keywords": [
            "Video data",
            "Information density",
            "video vs text information density AI training",
            "비디오 데이터 정보 밀도"
          ],
          "focus": "technical_spec",
          "academicRequired": true,
          "domainFilters": [
            "site:arxiv.org",
            "site:openai.com",
            "site:anthropic.com",
            "site:huggingface.co"
          ]
        }
      }
    ],
    "summary": {
      "totalClaims": 6,
      "verifiedClaims": 6,
      "overallScore": 0.99,
      "sourceTierDistribution": {
        "S": 3,
        "A": 2,
        "B": 3,
        "C": 3
      }
    },
    "allSources": [
      {
        "url": "https://www.youtube.com/watch?v=vV95Kq6NOfU",
        "title": "[OpenAI 본사 직격] \"GPT-5는 이미...\" 트랜스포머 공동 저자가 말하는 AI의 다음 단계 (EO 인터뷰)",
        "tier": "B",
        "domain": "www.youtube.com",
        "icon": "⚠️",
        "publishDate": "2024-11-25"
      },
      {
        "url": "https://podcasts.apple.com/us/podcast/the-mad-podcast-with-matt-turck/id1614210306",
        "title": "The MAD Podcast with Matt Turck: OpenAI's Łukasz Kaiser (Transformer Co-Author)",
        "tier": "C",
        "domain": "podcasts.apple.com",
        "icon": "",
        "publishDate": "2024-12-18"
      },
      {
        "url": "https://arxiv.org/abs/2406.15126",
        "title": "On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey",
        "tier": "S",
        "domain": "arxiv.org",
        "icon": "🏛️",
        "publishDate": "2024-06-21"
      },
      {
        "url": "https://www.dwarkeshpatel.com/p/lukasz-kaiser",
        "title": "Lukasz Kaiser - Transformers, Brain vs OpenAI, & World Models",
        "tier": "C",
        "domain": "www.dwarkeshpatel.com",
        "icon": "",
        "publishDate": "2024-05-30"
      },
      {
        "url": "https://youtu.be/S_f7v9S2y_8",
        "title": "Lukasz Kaiser: Transformers, Brain vs OpenAI, & World Models",
        "tier": "C",
        "domain": "youtu.be",
        "icon": "",
        "publishDate": "2024-05-30"
      },
      {
        "url": "https://www.youtube.com/watch?v=zGL8uf726lw",
        "title": "Lukasz Kaiser: Transformers, o1, and the Future of AI (Dwarkesh Podcast)",
        "tier": "B",
        "domain": "www.youtube.com",
        "icon": "⚠️",
        "publishDate": "2024-09-20"
      },
      {
        "url": "https://arxiv.org/abs/2307.15337",
        "title": "Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation",
        "tier": "S",
        "domain": "arxiv.org",
        "icon": "🏛️",
        "publishDate": "2023-07-28"
      },
      {
        "url": "https://openai.com/index/learning-to-reason-with-llms/",
        "title": "Learning to Reason with LLMs (OpenAI o1 Announcement)",
        "tier": "A",
        "domain": "openai.com",
        "icon": "🛡️",
        "publishDate": "2024-09-12"
      },
      {
        "url": "https://www.youtube.com/watch?v=vVka9PeyB8A",
        "title": "No Priors Ep. 65 | With OpenAI’s Lukasz Kaiser: The Transformer, GPT-4o and the future of reasoning",
        "tier": "B",
        "domain": "www.youtube.com",
        "icon": "⚠️",
        "publishDate": "2024-05-23"
      },
      {
        "url": "https://openai.com/index/video-generation-models-as-world-simulators/",
        "title": "Video generation models as world simulators (Sora Technical Report)",
        "tier": "A",
        "domain": "openai.com",
        "icon": "🛡️",
        "publishDate": "2024-02-15"
      },
      {
        "url": "https://arxiv.org/abs/2103.15691",
        "title": "ViViT: A Video Vision Transformer",
        "tier": "S",
        "domain": "arxiv.org",
        "icon": "🏛️",
        "publishDate": "2021-03-29"
      }
    ],
    "recommendation": "publish",
    "verificationSummary": "## 검증 요약\n- 총 주장: 6개\n- 검증 완료: 6개\n- 전체 점수: 99%\n\n## 출처 신뢰도 분포\n- 🏛️ Tier S (학술): 3개\n- 🛡️ Tier A (공식): 2개\n- ⚠️ Tier B (주의): 3개\n- Tier C (일반): 3개"
  },
  "translation": {
    "title_en": "트랜스포머의 아버지, 우카시 카이저 팟캐스트 정리",
    "title_ko": "트랜스포머의 아버지, 우카시 카이저 팟캐스트 정리",
    "content_en": "1. 아이디어와 검증의 병목(진행자가 연구의 가장 큰 병목이 무엇인지, 좋은 아이디어가 부족한 것인지 묻자)우카시 카이저:\n\"병목은 아이디어가 아닙니다. 아이디어는 넘쳐납니다.제 노트에만 해도 시도해보고 싶은 아이디어가 100개는 적혀 있습니다.진짜 병목은 '검증(Verification)'입니다.코드를 짜고, 실행해보고, 그게 실제로 작동하는지 확인하는 과정이죠.만약 AI가 이 코딩과 검증 과정을 대신해 줄 수 있다면, 연구 속도는 엄청나게 가속화될 겁니다.\"2. 코덱스(Codex)와 합성 데이터, 그리고 GPU(AI 코딩 도구를 얼마나 활용하는지, 그리고 합성 데이터가 도움이 되는지에 대해)우카시 카이저:\n\"저는 코덱스를 아주 많이 씁니다.GPU에 연결하고 실행하는 복잡한 과정들을 AI가 도와주죠.합성 데이터(Synthetic data)는 주로 추론 모델(Reasoning model)에서 나옵니다.이걸 사용하면 사전 학습(Pre-training) 모델을 개선하는 데 도움이 되긴 합니다.하지만 뭐, 속도가 2배 빨라졌다거나 그 정도의 혁명적인 수준은 아직 아닙니다.궁극적인 병목은 결국 GPU와 에너지입니다.돌려보고 싶은 실험은 너무 많은데 자원은 한정적이니까요.작은 모델로 실험해야 효율이 좋은데, 실험용으로 잘 준비된 작은 모델이 없는 경우가 많습니다.이런 준비 과정을 AI가 해준다면 분명 큰 도움이 될 겁니다.\"3. 계단식 발전 vs 외부에서의 폭발(기술 발전이 정체된 것처럼 보이다가 갑자기 튀어 오르는 현상에 대해)우카시 카이저:\n\"일하는 사람 입장에서는 발전이 '계단식(Step function)'으로 보입니다.다음 아이디어를 찾고 검증할 때까지 정체 구간이 있으니까요.하지만 밖에서 보면 이건 그냥 '폭발(Explosion)'처럼 보일 겁니다.내부의 계단 하나하나가 외부에서는 거대한 도약으로 나타나니까요.4. \"우리 소프트웨어는 별로다\" (구글, OpenAI의 현실)(거대 AI 기업들의 내부 코드 품질과 인프라에 대한 솔직한 고백)우카시 카이저:\n\"솔직히 말해서, 우리 소프트웨어는 별로입니다(Not good).구글도 그랬고, 오픈AI도 마찬가지입니다.연구자들은 빨리 결과를 보고 싶어 해서 코드를 엉망으로 짜놓기도 합니다.그래서 그걸 고치는 데(Refactoring) 엄청난 일을 해야 하죠.만약 AI 도구가 이 '고치는 작업'을 도와준다면 발전은 더 빨라질 겁니다. 그래서 아직 개선될 여지가 엄청나게 많이 남아있습니다.\"(대형 모델 훈련 시 발생하는 버그와 기술 부채에 대해)우카시 카이저:\n\"버그가 정말 많습니다.하지만 일단 훈련(Training run)을 시작하면 멈출 수가 없어서 그냥 밀고 나가야 합니다.그렇게 대형 모델 학습을 끝내고 나면, 고쳐야 할 게 산더미처럼 쌓여 있죠.이런 문제들을 해결해 나가고 있기 때문에, AI 발전이 멈추는 일은 없을 겁니다.\"5. 추론 모델과 멀티모달의 현재(o1 같은 추론 모델의 수준과 멀티모달 통합에 대해)우카시 카이저:\n\"추론 모델은 이제 막 초기 단계(Early days)입니다. 예를 들어 지금은 순차적으로 추론하지만, 병렬적으로(Parallel) 추론하는 등 효율화할 방법이 많습니다.멀티모달 학습도 이미 진행 중입니다.흥미로운 건 인코더만 수정했는데 텍스트 생성 능력도 유지되면서 손가락이 6개 나오던 문제도 개선되었다는 점입니다.비디오 생성 능력도 곧(Very soon), 어쩌면 오늘 당장이라도 놀라운 수준에 도달할 겁니다.\"6. 비디오 데이터의 한계와 월드 모델(인터넷의 비디오 데이터를 다 학습하면 AI가 세상을 완벽히 이해할지에 대해)우카시 카이저:\n\"영상은 굉장히 중복된 정보가 많습니다.텍스트는 정보 밀도가 높지만, 비디오는 픽셀 단위로는 많아도 '유의미한 정보'의 비율은 낮죠.하지만 비디오는 모델이 가진 '물리적 세계에 대한 구멍'을 메워주는 역할을 할 겁니다.\"언어 모델은 이미 '추상적인 월드 모델'이라고 생각합니다.물리적인 월드 모델(비디오 학습)은 로봇에게는 필수적이겠지만, 사무직 업무를 하는 에이전트(Agent)에게는 생각보다 덜 중요할 수도 있습니다.\"7. AGI와 미래 (개리 마커스, 샘 알트만)(추론 모델의 미래와 AGI 도달 가능성에 대해)우카시 카이저:\n\"추론 모델을 계속 개선하고, 이를 지속 학습(Continuous learning)과 결합한다면, 데미스 하사비스가 정의한 수준의 AGI에 도달할 수 있을 것이라 봅니다(1901년 데이터만 주고 상대성 이론을 맞출 수 있냐).\"(개리 마커스 같은 회의론자들의 비판에 대해)우카시 카이저:\n\"그들이 AI가 거품이라며 욕해도 전혀 타격 없습니다. 저는 그냥 제 할 일을 할 뿐입니다.\"(오픈AI CEO 샘 알트만에 대해)우카시 카이저:\n\"우리 CEO인 샘(Sam)에 대해 제가 생각하는 한 가지 훌륭한 점은,그는 일단 그냥 시도해 본다(just try)는 것입니다.사람들이 좋아하지 않을 만한 경로들도 많이 있겠지만, 그중 하나가 성공할 수도 있으니까요.(중략)그래서 저는 이 기술이 어떻게 대중화될지 스스로에게 묻지 않습니다.어쩌면 직장에서 유용하게 쓰일 수도 있고, 우리가 아직 발견하지 못한 다른 부분일 수도 있겠죠.샘은 그저 시도할 것입니다(마지막으로 AI가 가져올 미래에 대해)우카시 카이저:\n\"하지만 AI가 알아서 우리 삶을 낙원으로 바꿔줄 거라고는 보지 않습니다(sns를 예시로 들며).기술은 도구일 뿐이고, 낙원을 만드는 건 결국 우리 인간이 AI를 어떻게 쓰느냐에 달려 있습니다.\"요약된 부분이 많은데 번역본 보는걸 추천. 특뽕참 https://www.youtube.com/watch?v=SUYdL4K1GUk&t=7s트랜스포머의 아버지, 우카시 카이저: 추론은 이제 1층이다https://i.ytimg.com/vi/SUYdL4K1GUk/maxresdefault.jpg",
    "content_ko": "1. 아이디어와 검증의 병목(진행자가 연구의 가장 큰 병목이 무엇인지, 좋은 아이디어가 부족한 것인지 묻자)우카시 카이저:\n\"병목은 아이디어가 아닙니다. 아이디어는 넘쳐납니다.제 노트에만 해도 시도해보고 싶은 아이디어가 100개는 적혀 있습니다.진짜 병목은 '검증(Verification)'입니다.코드를 짜고, 실행해보고, 그게 실제로 작동하는지 확인하는 과정이죠.만약 AI가 이 코딩과 검증 과정을 대신해 줄 수 있다면, 연구 속도는 엄청나게 가속화될 겁니다.\"2. 코덱스(Codex)와 합성 데이터, 그리고 GPU(AI 코딩 도구를 얼마나 활용하는지, 그리고 합성 데이터가 도움이 되는지에 대해)우카시 카이저:\n\"저는 코덱스를 아주 많이 씁니다.GPU에 연결하고 실행하는 복잡한 과정들을 AI가 도와주죠.합성 데이터(Synthetic data)는 주로 추론 모델(Reasoning model)에서 나옵니다.이걸 사용하면 사전 학습(Pre-training) 모델을 개선하는 데 도움이 되긴 합니다.하지만 뭐, 속도가 2배 빨라졌다거나 그 정도의 혁명적인 수준은 아직 아닙니다.궁극적인 병목은 결국 GPU와 에너지입니다.돌려보고 싶은 실험은 너무 많은데 자원은 한정적이니까요.작은 모델로 실험해야 효율이 좋은데, 실험용으로 잘 준비된 작은 모델이 없는 경우가 많습니다.이런 준비 과정을 AI가 해준다면 분명 큰 도움이 될 겁니다.\"3. 계단식 발전 vs 외부에서의 폭발(기술 발전이 정체된 것처럼 보이다가 갑자기 튀어 오르는 현상에 대해)우카시 카이저:\n\"일하는 사람 입장에서는 발전이 '계단식(Step function)'으로 보입니다.다음 아이디어를 찾고 검증할 때까지 정체 구간이 있으니까요.하지만 밖에서 보면 이건 그냥 '폭발(Explosion)'처럼 보일 겁니다.내부의 계단 하나하나가 외부에서는 거대한 도약으로 나타나니까요.4. \"우리 소프트웨어는 별로다\" (구글, OpenAI의 현실)(거대 AI 기업들의 내부 코드 품질과 인프라에 대한 솔직한 고백)우카시 카이저:\n\"솔직히 말해서, 우리 소프트웨어는 별로입니다(Not good).구글도 그랬고, 오픈AI도 마찬가지입니다.연구자들은 빨리 결과를 보고 싶어 해서 코드를 엉망으로 짜놓기도 합니다.그래서 그걸 고치는 데(Refactoring) 엄청난 일을 해야 하죠.만약 AI 도구가 이 '고치는 작업'을 도와준다면 발전은 더 빨라질 겁니다. 그래서 아직 개선될 여지가 엄청나게 많이 남아있습니다.\"(대형 모델 훈련 시 발생하는 버그와 기술 부채에 대해)우카시 카이저:\n\"버그가 정말 많습니다.하지만 일단 훈련(Training run)을 시작하면 멈출 수가 없어서 그냥 밀고 나가야 합니다.그렇게 대형 모델 학습을 끝내고 나면, 고쳐야 할 게 산더미처럼 쌓여 있죠.이런 문제들을 해결해 나가고 있기 때문에, AI 발전이 멈추는 일은 없을 겁니다.\"5. 추론 모델과 멀티모달의 현재(o1 같은 추론 모델의 수준과 멀티모달 통합에 대해)우카시 카이저:\n\"추론 모델은 이제 막 초기 단계(Early days)입니다. 예를 들어 지금은 순차적으로 추론하지만, 병렬적으로(Parallel) 추론하는 등 효율화할 방법이 많습니다.멀티모달 학습도 이미 진행 중입니다.흥미로운 건 인코더만 수정했는데 텍스트 생성 능력도 유지되면서 손가락이 6개 나오던 문제도 개선되었다는 점입니다.비디오 생성 능력도 곧(Very soon), 어쩌면 오늘 당장이라도 놀라운 수준에 도달할 겁니다.\"6. 비디오 데이터의 한계와 월드 모델(인터넷의 비디오 데이터를 다 학습하면 AI가 세상을 완벽히 이해할지에 대해)우카시 카이저:\n\"영상은 굉장히 중복된 정보가 많습니다.텍스트는 정보 밀도가 높지만, 비디오는 픽셀 단위로는 많아도 '유의미한 정보'의 비율은 낮죠.하지만 비디오는 모델이 가진 '물리적 세계에 대한 구멍'을 메워주는 역할을 할 겁니다.\"언어 모델은 이미 '추상적인 월드 모델'이라고 생각합니다.물리적인 월드 모델(비디오 학습)은 로봇에게는 필수적이겠지만, 사무직 업무를 하는 에이전트(Agent)에게는 생각보다 덜 중요할 수도 있습니다.\"7. AGI와 미래 (개리 마커스, 샘 알트만)(추론 모델의 미래와 AGI 도달 가능성에 대해)우카시 카이저:\n\"추론 모델을 계속 개선하고, 이를 지속 학습(Continuous learning)과 결합한다면, 데미스 하사비스가 정의한 수준의 AGI에 도달할 수 있을 것이라 봅니다(1901년 데이터만 주고 상대성 이론을 맞출 수 있냐).\"(개리 마커스 같은 회의론자들의 비판에 대해)우카시 카이저:\n\"그들이 AI가 거품이라며 욕해도 전혀 타격 없습니다. 저는 그냥 제 할 일을 할 뿐입니다.\"(오픈AI CEO 샘 알트만에 대해)우카시 카이저:\n\"우리 CEO인 샘(Sam)에 대해 제가 생각하는 한 가지 훌륭한 점은,그는 일단 그냥 시도해 본다(just try)는 것입니다.사람들이 좋아하지 않을 만한 경로들도 많이 있겠지만, 그중 하나가 성공할 수도 있으니까요.(중략)그래서 저는 이 기술이 어떻게 대중화될지 스스로에게 묻지 않습니다.어쩌면 직장에서 유용하게 쓰일 수도 있고, 우리가 아직 발견하지 못한 다른 부분일 수도 있겠죠.샘은 그저 시도할 것입니다(마지막으로 AI가 가져올 미래에 대해)우카시 카이저:\n\"하지만 AI가 알아서 우리 삶을 낙원으로 바꿔줄 거라고는 보지 않습니다(sns를 예시로 들며).기술은 도구일 뿐이고, 낙원을 만드는 건 결국 우리 인간이 AI를 어떻게 쓰느냐에 달려 있습니다.\"요약된 부분이 많은데 번역본 보는걸 추천. 특뽕참 https://www.youtube.com/watch?v=SUYdL4K1GUk&t=7s트랜스포머의 아버지, 우카시 카이저: 추론은 이제 1층이다https://i.ytimg.com/vi/SUYdL4K1GUk/maxresdefault.jpg",
    "translatedAt": "2026-01-11T00:50:03.130Z",
    "slug": "930168"
  },
  "structured": {
    "type": "opinion",
    "content_ko": "AI 발전의 병목은 아이디어 부족이 아니다. 진짜 문제는 검증 속도다. 우카시 카이저는 이 과정을 AI가 해결할 것이라 단언한다.\n\n## 근거\n오픈AI와 구글의 내부 코드는 엉망이다. 연구자들은 결과 도출을 위해 기술 부채를 방치한다. 우카시 카이저의 노트에는 미검증 아이디어가 100개나 쌓여 있다. 대형 모델 훈련 중 버그가 발생해도 멈추지 않고 강행한다.\n\nGPU와 에너지는 가장 큰 물리적 제약이다. 현재 실험에 최적화된 작은 모델이 부족한 실정이다. AI가 리팩토링과 실험 준비를 도와야 연구가 가속한다. 검증 자동화는 정체된 것처럼 보이는 발전을 폭발로 바꾼다.\n\n## 반론\n비디오 데이터는 정보 밀도가 매우 낮다. 텍스트와 달리 중복된 픽셀 정보가 대다수를 차지한다. 물리적 세계 이해에는 필수적이나 사무직 에이전트에겐 덜 중요하다.\n\n## FAQ\nQ: 합성 데이터가 프리트레이닝 모델을 근본적으로 바꾸나?  \nA: 추론 모델 개선엔 유용하나 아직 혁명적인 수준은 아니다.\n\nQ: o1 같은 추론 모델은 어느 단계인가?  \nA: 이제 1층에 도달한 초기 단계다. 병렬 추론 등 최적화 가능성이 무궁무진하다.\n\nQ: AGI 도달이 정말 가능한가?  \nA: 지속 학습과 추론 모델이 결합하면 가능하다. 데미스 하사비스의 정의를 충족할 것이다.\n\n## 결론\n발전은 내부에서 계단식이나 외부에서는 폭발로 보인다. 샘 알트만은 비판에 굴하지 않고 계속 시도한다. 낙원을 만드는 것은 도구가 아닌 인간의 몫이다. 지금 당장 AI 도구로 자신의 기술 부채부터 해결하라.",
    "content_en": "The bottleneck in AI advancement is not a lack of ideas. The real issue is the speed of verification. Łukasz Kaiser asserts that AI will be the one to solve this process.\n\n## Rationale\nInternal code at OpenAI and Google is a mess. Researchers neglect technical debt to prioritize producing results. Łukasz Kaiser’s notes contain a backlog of a hundred unverified ideas. Even when bugs occur during the training of large models, they push through without stopping.\n\nGPUs and energy are the primary physical constraints. There is currently a shortage of small models optimized for experimentation. Research will accelerate when AI assists with refactoring and experimental preparation. Automating verification will transform seemingly stagnant progress into an explosion.\n\n## Counterargument\nVideo data has extremely low information density. Unlike text, the majority of it consists of redundant pixel information. While essential for understanding the physical world, it is less critical for white-collar agents.\n\n## FAQ\nQ: Does synthetic data fundamentally change pre-training models?  \nA: It is useful for improving reasoning models, but it is not yet at a revolutionary level.\n\nQ: What stage are reasoning models like o1 currently in?  \nA: they are in the early stages, having just reached the \"first floor.\" There is vast potential for optimization, such as parallel reasoning.\n\nQ: Is reaching AGI truly possible?  \nA: It is possible if continuous learning and reasoning models are combined. It will meet Demis Hassabis's definition.\n\n## Conclusion\nProgress is incremental internally, but it appears as an explosion from the outside. Sam Altman continues to push forward, undeterred by criticism. Creating a paradise is the responsibility of humans, not tools. Start addressing your own technical debt with AI tools right now.",
    "title_ko": "AI 발전의 병목, '검증 속도'가 핵심이다",
    "title_en": "AI's True Bottleneck Is Verification Speed Not Ideas",
    "description_ko": "연구자들은 왜 엉망인 코드를 방치할까? AI 발전 정체를 돌파할 '자동 검증'의 핵심 가치를 공개합니다.",
    "description_en": "Discover why verification speed determines the winner of the AI race. Learn how AI tools can finally fix technical debt."
  }
}