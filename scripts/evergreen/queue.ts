export type EvergreenSeed = {
  id: string;
  title: string;
  description: string;
  keyInsights: string[];
  researchQuestions: string[];
};

export const EVERGREEN_QUEUE: EvergreenSeed[] = [
  {
    id: 'mcp-intro',
    title: 'MCP(Model Context Protocol) 입문 가이드',
    description: 'MCP가 무엇인지, 왜 “에이전트 통합 표준”으로 부상하는지, 도입 시 무엇부터 점검해야 하는지 정리한다.',
    keyInsights: [
      '도구 호출(tool calling)·컨텍스트 주입의 “연결 규격”을 표준화하면, 모델/클라이언트 교체 비용이 줄어든다.',
      '보안·권한·감사 로그가 같이 설계되지 않으면 MCP 도입이 오히려 공격 표면을 넓힐 수 있다.',
    ],
    researchQuestions: [
      'Model Context Protocol(MCP)의 목표와 핵심 구성요소(서버/클라이언트/툴/리소스)는 무엇인가?',
      'MCP에서 권한/승인/감사 로그(guardrails)를 어떻게 설계하는 것이 권장되는가?',
      '기존 “모델별 플러그인/툴콜” 방식 대비 MCP 도입의 운영상 장단점은 무엇인가?',
    ],
  },
  {
    id: 'prompt-injection-defense',
    title: '프롬프트 인젝션 방어 체크리스트',
    description: '현실에서 자주 발생하는 프롬프트 인젝션/데이터 유출 패턴을 정리하고, 제품·에이전트 레벨에서의 방어책을 제시한다.',
    keyInsights: [
      '인젝션은 “모델이 속아서”라기보다, 입력 경계/권한 경계가 없는 시스템 설계 문제로 번지는 경우가 많다.',
      '툴콜·브라우징·파일 접근이 붙는 순간, 방어는 프롬프트가 아니라 정책/권한/검증 레이어로 이동한다.',
    ],
    researchQuestions: [
      '프롬프트 인젝션의 대표적 공격 유형(지시 탈취, 데이터 유출, 정책 우회)은 무엇인가?',
      '주요 LLM 제공자/보안 가이드에서 권장하는 완화 전략(allowlist, sandbox, output validation)은 무엇인가?',
      '툴 사용 에이전트에서 데이터 유출을 막기 위한 권한 모델/검증 체계는 어떻게 설계해야 하는가?',
    ],
  },
  {
    id: 'rag-pipeline-basics',
    title: 'RAG 파이프라인 구성 가이드',
    description: '인덱싱→검색→생성까지의 기본 구성 요소를 정리하고, “정확도”를 떨어뜨리는 흔한 실패 패턴을 피하는 방법을 다룬다.',
    keyInsights: [
      'RAG 품질은 모델 성능보다 “문서 분할·메타데이터·검색 쿼리” 설계에 더 크게 좌우된다.',
      '권한/버전/변경이력 같은 운영 메타데이터가 없으면, 답변은 맞아도 서비스는 위험해진다.',
    ],
    researchQuestions: [
      'RAG의 핵심 구성요소(ingestion, chunking, embedding, retrieval, generation)에서 흔한 실패 원인은 무엇인가?',
      '검색 단계에서 precision/recall을 개선하기 위한 대표 기법(하이브리드 검색, reranking)은 무엇인가?',
      '운영 환경에서 RAG 문서 업데이트/삭제/권한 변경을 안전하게 반영하는 방법은 무엇인가?',
    ],
  },
  {
    id: 'rag-evals',
    title: 'RAG 평가(Evals) 실전 가이드',
    description: 'RAG는 “그럴듯함”이 아니라 재현 가능한 평가로 관리해야 한다. 실무에서 통하는 평가 지표와 운영 루프를 정리한다.',
    keyInsights: [
      '정답률만 보면 실패한다. 근거 적합성(grounding)·출처 일치·회수율을 분리해 봐야 한다.',
      '평가는 데이터셋이 아니라 “업무 질문”에서 시작해야 유지된다.',
    ],
    researchQuestions: [
      'RAG 평가에서 자주 쓰이는 지표(groundedness, faithfulness, retrieval recall 등)는 무엇인가?',
      '자동 평가(LLM-as-judge)에서 편향/누수/과적합 위험을 줄이는 방법은 무엇인가?',
      '프로덕션에서 RAG 품질을 모니터링/회귀 테스트하는 운영 패턴은 무엇인가?',
    ],
  },
  {
    id: 'agent-memory',
    title: 'LLM 에이전트 메모리 설계 가이드',
    description: '에이전트의 “기억”은 대화 저장이 아니라 제품 기능이다. 단기/장기/업무 메모리를 어떻게 나눠 설계할지 정리한다.',
    keyInsights: [
      '무제한 저장은 리스크다. 저장 범위·보존 기간·삭제 정책을 먼저 정의해야 한다.',
      '메모리는 모델이 아니라 “검색/요약/적재/회수” 파이프라인의 문제다.',
    ],
    researchQuestions: [
      '에이전트 메모리의 대표 패턴(요약 메모리, 벡터 메모리, 규칙 기반 메모리)은 무엇인가?',
      '개인정보/민감정보가 포함될 수 있는 메모리를 안전하게 저장/삭제하기 위한 원칙은 무엇인가?',
      '메모리 회수(retrieval)가 오류를 만드는 대표 원인과 완화 방법은 무엇인가?',
    ],
  },
  {
    id: 'tool-calling-guardrails',
    title: '툴콜링(도구 호출) 권한 모델 정리',
    description: '에이전트가 외부 API·DB·파일을 만질수록 “무엇을 할 수 있는가”를 코드로 제한해야 한다. 권한 모델을 실무 관점에서 정리한다.',
    keyInsights: [
      '툴콜은 “기능”이 아니라 “권한”이다. 호출 가능 도구를 최소화하고 목적별로 분리해야 한다.',
      '출력 검증(JSON schema 등) 없이 자동 실행을 붙이면 작은 오류가 큰 사고로 이어진다.',
    ],
    researchQuestions: [
      '툴콜 에이전트에서 권한을 최소화(least privilege)하기 위한 대표 설계는 무엇인가?',
      '출력 포맷 강제/검증(JSON schema, validators)로 안전성을 높이는 방법은 무엇인가?',
      '감사 로그/리플레이(재현) 체계를 구축할 때 필수로 남겨야 하는 메타데이터는 무엇인가?',
    ],
  },
  {
    id: 'llm-cost-optimization',
    title: 'LLM 비용 최적화 가이드',
    description: '토큰 비용은 곧 제품 마진이다. 캐시·배치·요약·라우팅으로 비용을 낮추는 실전 전략을 정리한다.',
    keyInsights: [
      '비용 최적화는 “덜 쓰기”가 아니라 “같은 품질을 더 싸게”다. 품질 지표와 함께 움직여야 한다.',
      '라우팅(간단 질의→저가 모델, 복잡 질의→고성능 모델)은 가장 큰 레버지만 실패하면 품질이 무너진다.',
    ],
    researchQuestions: [
      'LLM 비용을 줄이는 대표 전략(캐시, 배치, 요약, 라우팅)의 효과/리스크는 무엇인가?',
      '프롬프트 길이/컨텍스트 설계가 비용과 품질에 미치는 영향은 무엇인가?',
      '프로덕션에서 비용과 품질을 동시에 모니터링하는 지표 설계는 어떻게 해야 하는가?',
    ],
  },
  {
    id: 'model-routing',
    title: '모델 라우팅 전략: 비용과 성능을 섞는 법',
    description: '한 모델로 끝내지 않는 시대다. 업무 난이도·리스크·지연시간에 따라 모델을 분기하는 라우팅 전략을 정리한다.',
    keyInsights: [
      '라우터는 “분류기”다. 분류 실패가 곧 품질/비용 폭발로 이어진다.',
      '에러 버짓과 사용자 기대치가 다르므로, 기능별 SLA를 먼저 정의해야 한다.',
    ],
    researchQuestions: [
      '모델 라우팅(다중 모델 오케스트레이션)에서 일반적으로 쓰이는 분기 기준은 무엇인가?',
      '라우팅의 대표 실패 모드(난이도 오판, 긴급도 오판, 정책 위반)를 줄이는 방법은 무엇인가?',
      '기업 환경에서 모델 라우팅을 적용할 때 거버넌스/감사 요구사항은 무엇인가?',
    ],
  },
  {
    id: 'finetune-vs-rag',
    title: '파인튜닝 vs RAG 선택 가이드',
    description: '“학습할 것인가, 검색할 것인가”는 제품 전략이다. 비용·품질·운영 복잡도를 기준으로 선택 프레임을 제시한다.',
    keyInsights: [
      'RAG는 최신성/출처를 얻고, 파인튜닝은 문체/행동을 고정한다. 목적이 다르다.',
      '둘을 섞을 때는 평가 루프가 없으면 재현성이 무너진다.',
    ],
    researchQuestions: [
      '파인튜닝과 RAG가 각각 강점을 가지는 문제 유형은 무엇인가?',
      '파인튜닝 데이터 품질/보안/라이선스 측면에서 주의해야 할 점은 무엇인가?',
      '하이브리드(RAG+파인튜닝) 설계에서 흔한 함정과 운영 방법은 무엇인가?',
    ],
  },
  {
    id: 'hallucination-playbook',
    title: 'LLM 환각 줄이기 실전 플레이북',
    description: '환각은 “모델 문제”로만 보면 해결이 늦다. 제품·프롬프트·검증 레이어로 나눠 줄이는 방법을 정리한다.',
    keyInsights: [
      '환각은 입력 불충분/검색 실패/출력 포맷 실패 등 시스템 결함이 겹쳐서 발생한다.',
      '“모른다”를 말하게 만들려면, 실패를 허용하는 UX와 정책이 먼저다.',
    ],
    researchQuestions: [
      'LLM 환각을 줄이기 위한 대표 접근(검색 기반 grounding, self-check, verification)은 무엇인가?',
      '출력 포맷 강제/검증이 환각을 줄이는 데 어떤 역할을 하는가?',
      '프로덕션에서 환각을 측정하고 회귀를 막는 운영 지표는 무엇인가?',
    ],
  },
  {
    id: 'on-device-ai-npu',
    title: '온디바이스 AI/NPU 기초 정리',
    description: '온디바이스 AI는 개인정보·지연시간·비용 구조를 바꾼다. NPU의 역할과 제품 설계 포인트를 정리한다.',
    keyInsights: [
      '온디바이스는 “빠름”만이 아니라 “데이터 경계”를 바꾼다. 어떤 데이터가 기기 밖으로 나가면 안 되는지부터 정의해야 한다.',
      '모델 최적화(양자화/프루닝/캐시) 없이는 배터리·발열·성능을 동시에 만족시키기 어렵다.',
    ],
    researchQuestions: [
      'NPU/가속기의 역할과 GPU/CPU 대비 장단점은 무엇인가?',
      '온디바이스 모델 배포에서 대표 최적화(양자화, distillation)와 트레이드오프는 무엇인가?',
      '온디바이스/클라우드 하이브리드 제품 설계에서 흔한 설계 패턴은 무엇인가?',
    ],
  },
  {
    id: 'agent-observability',
    title: '에이전트 관측성(Observability) 구축 가이드',
    description: '에이전트는 “왜 그렇게 했는지”가 중요하다. 로그/트레이스/리플레이를 어떻게 설계할지 정리한다.',
    keyInsights: [
      '관측성이 없으면, 동일한 버그를 같은 비용으로 계속 재현하게 된다.',
      '프롬프트/툴콜/검색 결과/결정 기준을 같이 저장해야 디버깅이 된다.',
    ],
    researchQuestions: [
      '에이전트 시스템에서 필수로 수집해야 하는 관측성 데이터(프롬프트, 툴콜, 검색 결과 등)는 무엇인가?',
      '개인정보/보안 이슈를 고려한 로그 마스킹/보관 정책은 어떻게 설계해야 하는가?',
      '리플레이(재현) 가능한 로그를 남기기 위한 최소 메타데이터는 무엇인가?',
    ],
  },
  {
    id: 'structured-output',
    title: 'LLM 구조화 출력(JSON) 강제 가이드',
    description: '모델이 “그럴듯한 글”이 아니라 “검증 가능한 출력”을 내게 하려면 포맷을 강제해야 한다. JSON 스키마/검증을 중심으로 정리한다.',
    keyInsights: [
      '구조화 출력은 품질 개선보다 “안전한 자동화”를 위해 필요하다.',
      '스키마 검증 실패를 복구하는 재시도 전략이 없으면, 자동화 파이프라인이 쉽게 깨진다.',
    ],
    researchQuestions: [
      'LLM 출력 포맷을 구조화(JSON schema 등)하는 대표 접근은 무엇인가?',
      '스키마 검증 실패 시 재시도/수정 루프를 설계하는 방법은 무엇인가?',
      '구조화 출력이 보안(인젝션/권한)과 운영(관측성/테스트)에 주는 효과는 무엇인가?',
    ],
  },
  {
    id: 'rag-access-control',
    title: '권한 기반 RAG(문서 권한 유지) 정리',
    description: 'RAG에서 가장 위험한 문제는 “정답률”이 아니라 권한 없는 문서가 섞이는 것이다. 권한 기반 검색 설계를 정리한다.',
    keyInsights: [
      '검색은 권한을 “상속”해야 한다. 생성 단계에서 마스킹하는 방식은 늦다.',
      '권한/테넌시를 벡터 인덱스 구조에 반영하지 않으면 운영 난이도가 급상승한다.',
    ],
    researchQuestions: [
      '권한 기반 검색(ABAC/RBAC)을 RAG 파이프라인에 적용하는 대표 패턴은 무엇인가?',
      '테넌트 분리(멀티테넌시)에서 인덱스/쿼리 설계의 트레이드오프는 무엇인가?',
      '권한 누수를 탐지하기 위한 테스트/감사(샘플링, 리플레이) 방법은 무엇인가?',
    ],
  },
  {
    id: 'vector-db-choosing',
    title: '벡터DB 선택 기준(정확도·비용·운영)',
    description: 'RAG에 벡터DB를 붙이기 전, 무엇을 기준으로 비교해야 하는지 정리한다. 성능보다 운영(백업/권한/모니터링)을 먼저 본다.',
    keyInsights: [
      '“검색 품질”은 DB 이름이 아니라 인덱싱/스키마/쿼리 설계에서 갈린다.',
      '운영 요구(백업, 삭제, 권한, 비용 예측)가 충족되지 않으면 결국 교체한다.',
    ],
    researchQuestions: [
      '벡터 검색 시스템에서 인덱스 타입/파라미터가 성능에 미치는 영향은 무엇인가?',
      '운영 관점에서 반드시 확인해야 할 체크리스트(백업, 삭제, 권한, 모니터링)는 무엇인가?',
      '하이브리드 검색(키워드+벡터)과 reranking 조합은 어떤 상황에서 유리한가?',
    ],
  },
  {
    id: 'reranking-playbook',
    title: 'Retrieval Reranking 적용 플레이북',
    description: 'RAG에서 “찾았는데도 틀린다”는 대부분 reranking으로 개선된다. 적용 포인트와 실패 패턴을 정리한다.',
    keyInsights: [
      'reranking은 품질을 올리지만 지연시간과 비용을 늘린다. 적용 지점이 중요하다.',
      '평가 데이터가 없으면 reranker는 “좋아진 것처럼 보이는” 착시를 만든다.',
    ],
    researchQuestions: [
      'reranking 모델의 역할과 1차 검색 대비 기대 효과는 무엇인가?',
      'reranking을 도입할 때 지연시간/비용을 관리하는 전략(캐시, 후보 수 제한)은 무엇인가?',
      'reranking 품질을 검증하기 위한 평가 셋/지표는 어떻게 구성하는가?',
    ],
  },
  {
    id: 'eval-dataset',
    title: 'LLM 평가 데이터셋 만드는 법(사내 QA→Evals)',
    description: '벤치마크는 남의 일이다. 사내 질문/CS/운영 로그를 “평가 자산”으로 바꾸는 방법을 정리한다.',
    keyInsights: [
      '평가셋은 정답보다 “의도/채점 기준”이 핵심이다.',
      '업데이트마다 회귀가 생기므로, 최소한의 자동화된 회귀 테스트가 필요하다.',
    ],
    researchQuestions: [
      '실무 평가셋을 구성할 때 필요한 필드(의도, 정답, 채점 기준, 난이도)는 무엇인가?',
      'LLM-as-judge를 쓰는 경우 신뢰도를 높이기 위한 가이드라인은 무엇인가?',
      '프로덕션 업데이트에서 회귀 테스트를 운영하는 대표 패턴은 무엇인가?',
    ],
  },
  {
    id: 'open-source-serving',
    title: '오픈소스 LLM 배포(Serving) 가이드',
    description: '오픈소스 모델을 직접 띄우는 순간, 성능과 비용은 엔지니어링 문제가 된다. 추론 서버 선택과 운영 포인트를 정리한다.',
    keyInsights: [
      '서빙은 모델만이 아니라 배치/캐시/토크나이저/스트리밍까지 포함한 시스템이다.',
      '모델 교체가 잦으면, 인터페이스 표준화(OpenAI-compatible 등)가 운영 비용을 줄인다.',
    ],
    researchQuestions: [
      '오픈소스 LLM 서빙에서 널리 쓰이는 추론 서버/런타임의 특징은 무엇인가?',
      '배치 처리, KV 캐시, 스트리밍이 지연시간/비용에 미치는 영향은 무엇인가?',
      '운영 관점(롤백, 버전 관리, 모니터링)에서 필수로 준비할 항목은 무엇인가?',
    ],
  },
  {
    id: 'gpu-inference-optimization',
    title: 'GPU 추론 최적화 기초: 지연·비용 줄이기',
    description: 'LLM 서비스는 결국 GPU 시간 싸움이다. 추론 최적화의 기본(배치·캐시·양자화)을 정리한다.',
    keyInsights: [
      '지연시간은 “모델”뿐 아니라 토크나이저/네트워크/큐잉에서 크게 튄다.',
      '양자화는 비용을 낮추지만, 품질 저하를 평가로 통제해야 한다.',
    ],
    researchQuestions: [
      'LLM 추론 지연시간을 구성하는 주요 요소(프리필/디코딩, 배치, 큐잉)는 무엇인가?',
      'KV 캐시 및 배치 전략이 처리량/지연시간에 미치는 영향은 무엇인가?',
      '양자화/프루닝/디스틸레이션의 대표 트레이드오프는 무엇인가?',
    ],
  },
  {
    id: 'governance-enterprise',
    title: '기업용 AI 거버넌스(정책/감사) 체크리스트',
    description: 'AI를 “썼다”가 아니라 “운영한다”로 넘어가면 거버넌스가 필요하다. 정책·감사·승인 프로세스를 정리한다.',
    keyInsights: [
      '거버넌스는 혁신을 막는 문서가 아니라, 실패 비용을 낮추는 장치다.',
      '권한/로그/삭제 요청이 제품 기능으로 들어가지 않으면 규정 대응이 어려워진다.',
    ],
    researchQuestions: [
      '기업 환경에서 AI 거버넌스에 포함되는 대표 항목(데이터, 보안, 책임, 감사)은 무엇인가?',
      '모델/프롬프트 변경에 대한 승인·롤백·감사 체계를 어떻게 구축하는가?',
      '사용자 데이터 처리(보관/삭제/옵트아웃) 관점에서 필요한 기능은 무엇인가?',
    ],
  },
  {
    id: 'agent-testing',
    title: '에이전트 테스트 하네스 구축 가이드',
    description: '에이전트는 테스트 없이는 운영이 불가능하다. 시나리오 테스트, 회귀, 시뮬레이션을 어떻게 구축할지 정리한다.',
    keyInsights: [
      '테스트는 “정답”보다 “실패 패턴”을 재현하는 데 초점을 둬야 한다.',
      '툴콜/검색/메모리까지 포함한 통합 테스트가 없으면 배포할수록 불안해진다.',
    ],
    researchQuestions: [
      '에이전트 테스트에서 시나리오/상태/툴 모킹을 설계하는 대표 방법은 무엇인가?',
      '회귀 테스트를 자동화하기 위한 데이터셋/리플레이 접근은 무엇인가?',
      '에이전트 평가에서 흔히 쓰이는 지표(성공률, 비용, 지연, 안전)를 어떻게 정의하는가?',
    ],
  },
  {
    id: 'prompt-template-versioning',
    title: '프롬프트 템플릿 버전 관리 방법',
    description: '프롬프트는 코드다. 변경 이력·실험·롤백·환경별 설정을 어떻게 관리하는지 정리한다.',
    keyInsights: [
      '“프롬프트 파일 하나”로는 운영이 안 된다. 버전/실험/가드레일이 필요하다.',
      '템플릿과 정책(금지/허용)은 분리해야 유지 보수가 된다.',
    ],
    researchQuestions: [
      '프롬프트를 코드처럼 버전 관리하기 위한 대표 패턴(템플릿, 변수, 환경 분리)은 무엇인가?',
      'A/B 테스트와 롤백을 포함한 프롬프트 실험 운영 방법은 무엇인가?',
      '안전 정책(금지/허용)과 프롬프트 텍스트를 분리하는 이유와 방법은 무엇인가?',
    ],
  },
  {
    id: 'ai-monitoring-metrics',
    title: 'LLM/에이전트 운영 지표(모니터링) 정리',
    description: 'DAU가 아니라 “품질과 비용”이 생존을 가른다. 프로덕션에서 꼭 봐야 하는 운영 지표를 정리한다.',
    keyInsights: [
      '품질 지표(정확도/근거/안전)와 비용 지표(토큰/지연/실패율)를 같이 봐야 한다.',
      '지표가 없으면 최적화가 아니라 “감”으로 운영하게 된다.',
    ],
    researchQuestions: [
      'LLM 서비스에서 일반적으로 모니터링하는 핵심 지표(지연, 비용, 성공률, 안전)는 무엇인가?',
      '환각/근거 부적합을 탐지하기 위한 실무적 방법(샘플링, 라벨링, 자동 평가)은 무엇인가?',
      '경보(알림)와 대응(롤백/차단)을 연결하는 운영 프로세스는 어떻게 설계하는가?',
    ],
  },
  {
    id: 'fine-tuning-data-licensing',
    title: '파인튜닝 데이터 라이선스/저작권 체크',
    description: '모델을 학습시키는 순간, 데이터는 법·계약·컴플라이언스 문제가 된다. 실무에서 놓치기 쉬운 체크리스트를 정리한다.',
    keyInsights: [
      '데이터는 기술 자산이자 법적 리스크다. 출처/권한/보관을 같이 관리해야 한다.',
      '외부 데이터는 “썼다”가 아니라 “증명했다”가 중요하다.',
    ],
    researchQuestions: [
      '파인튜닝 데이터 수집/사용에서 일반적으로 요구되는 라이선스/동의/계약 요소는 무엇인가?',
      '저작권/개인정보가 섞일 수 있는 데이터셋을 안전하게 관리하는 방법은 무엇인가?',
      '기업에서 데이터 출처 증빙과 감사 가능성을 확보하기 위한 운영 방법은 무엇인가?',
    ],
  },
  {
    id: 'korea-policy-monitoring',
    title: '국내 AI 정책/규제 모니터링 방법',
    description: '정책은 느리게 움직이지만, 한번 바뀌면 제품이 멈춘다. 국내 AI 규제/가이드 변화 감지 방법을 정리한다.',
    keyInsights: [
      '정책 변경은 기술보다 “배포/운영”에 먼저 영향을 준다.',
      '공식 문서·보도자료·가이드라인을 한곳에서 추적하는 루틴이 필요하다.',
    ],
    researchQuestions: [
      '국내에서 AI 관련 정책/가이드라인을 발표하는 주요 기관과 공식 채널은 무엇인가?',
      '제품팀이 정책 변경을 놓치지 않기 위한 모니터링/알림 운영 방법은 무엇인가?',
      '정책 대응을 위한 최소 문서(데이터 흐름도, 위험 평가, 로그 정책)는 무엇인가?',
    ],
  },
];
