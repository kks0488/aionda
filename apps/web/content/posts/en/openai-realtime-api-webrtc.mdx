---
title: 'OpenAI Realtime API & WebRTC: Conquering Voice AI Latency'
slug: openai-realtime-api-webrtc
date: '2025-12-17'
locale: en
excerpt: >-
  WebRTC support has been added to the OpenAI Realtime API. Now, ultra-low
  latency voice conversations are possible in web browsers and mobile apps. We
  analyze the technical implications.
tags:
  - OpenAI
  - Realtime API
  - WebRTC
  - Voice AI
  - Audio
coverImage: /images/posts/openai-realtime-api-webrtc.jpeg
category: Technology
author: AI Onda
sourceUrl: 'https://platform.openai.com/docs/changelog'
alternateLocale: /ko/posts/openai-realtime-api-webrtc
---

Did you find the subtle delay in voice conversations with AI frustrating? (Problem)
In December 2025, OpenAI officially started **supporting WebRTC connection methods in the Realtime API**. (Solution)
This drastically reduces network latency compared to existing WebSocket methods, enabling instant reaction speeds (Low Latency) akin to talking to a human. (Evidence)

## Changes Brought by WebRTC

### 1. Browser Native Support
You can open audio/video channels directly with AI models through WebRTC, a browser standard technology, without separate complex audio stream processing. Development difficulty decreases while quality increases.

### 2. Seamless Conversation (Interruptibility)
The reaction speed at which the AI detects and stops speaking when a user interrupts or cuts in (Barge-in) has dramatically improved. Natural 'back-and-forth' becomes possible.

### 3. Multimodal Streaming
Not just voice, but video feeds can also be transmitted in real-time. For example, it becomes possible to implement a service where you point a camera at a math problem and talk to an AI tutor in real-time.

## gpt-realtime-mini Model
The simultaneously released `gpt-realtime-mini` model maximizes cost-efficiency, opening the way for large-scale B2C services to adopt voice AI without burden.
