---
title: 'Lukasz Kaiser of OpenAI: ''The Real Bottleneck is Verification, Not Ideas'''
date: '2026-01-10'
excerpt: >-
  Transformer co-author Lukasz Kaiser shares a candid look inside OpenAI.
  Discover why AI development feels incremental and why coding agents are the
  key to the next explosion.
tags:
  - OpenAI
  - Lukasz Kaiser
  - AI Development
  - Coding Agents
  - Verification
coverImage: /images/posts/lukasz-kaiser-openai-verification-bottleneck.jpeg
category: Technology
author: AI Onda
sourceUrl: 'https://gall.dcinside.com/mgallery/board/view/?id=thesingularity&no=930168'
alternateLocale: /ko/posts/lukasz-kaiser-openai-verification-bottleneck
---

## 1. Why is AI Progress Hitting a Wall?

(Problem) While we see new AI breakthroughs every day, why does it feel like progress is stalling in a "step function" manner? (Solution) Lukasz Kaiser, co-author of the seminal Transformer paper, identifies 'Verification' as the primary bottleneck. (Evidence) He revealed that while he has over 100 ideas in his notebook, the process of writing code, running experiments, and verifying if they actually work is what slows down research the most.

## 2. A Candid Admission: \"Our Software is Not Good\"

In a surprising reveal, Kaiser admitted that the internal code at top AI labs like OpenAI and Google is often "not good."

1. **Technical Debt**: Researchers prioritize speed over code quality to see results faster, leading to a massive accumulation of bugs.
2. **The Refactoring Burden**: A significant portion of current AI advancement is spent on fixing and refactoring this suboptimal code.
3. **Training Inertia**: Once a training run startsâ€”costing millions of dollarsâ€”it cannot be stopped, forcing researchers to push through despite known bugs.

**ðŸ‘‰ Take Action Now**: Don't get paralyzed by code quality in your own projects. Follow Kaiser's lead: execute first, then use AI tools like Cursor or Claude Code to refactor later.

## 3. Why 'Coding Agents' are the Key to AGI

Kaiser predicts that the research pace will explode once AI moves beyond writing text to **autonomously coding and verifying experiments.**

- **The Limits of Synthetic Data**: Simply generating data has a ceiling for model improvement.
- **Accelerating the Loop**: If AI can prepare experimental models and verify code, researchers can test 100 ideas simultaneously.
- **The Perception of Explosion**: What looks like a step function internally will appear as a technological "explosion" to the outside world once the verification bottleneck is cleared.

## 4. Common Mistake: Waiting for the Next Giant Model

Many people fall into the trap of waiting for GPT 5.2 to solve all their problems.

- **Mistake**: Assuming a smarter model will automatically automate your specific workflow.
- **Why it Fails**: The real breakthrough comes from creating a 'Domain-Specific Verification Loop'.
- **The Correct Way**: Start using tools like Cursor or Claude Code today to build environments where AI can verify your specific business logic.

---

### FAQ

**Q1: Who is Lukasz Kaiser?**
A: He is one of the eight authors of the "Attention Is All You Need" paper and currently a key researcher at OpenAI.

**Q2: Will AI refactoring really speed up AGI?**
A: Yes. Kaiser emphasized that fixing internal infrastructure is a massive untapped opportunity for acceleration.

**Q3: When will we see the next level of Video Generation?**
A: He mentioned it could be "very soon"â€”perhaps as early as todayâ€”that we see surprising leaps in video intelligence.
