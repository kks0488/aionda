---
title: "Integrate LLM as Extended Unconscious While Maintaining Strict Human Verification"
slug: "a-helpful-way-to-think-about-llms"
date: "2026.01.10 04:11:56"
locale: "en"
description: "Large Language Models (LLMs) are not external knowledge repositories; they are tools that extend your unconscious thought. Do not externalize LLMs; instead, int"
tags: ["opinion"]
author: "Singularity Blog"
sourceId: "929863"
sourceUrl: "https://gall.dcinside.com/mgallery/board/view/?id=thesingularity&no=929863"
verificationScore: 0.57
alternateLocale: "/ko/posts/a-helpful-way-to-think-about-llms"
coverImage: "/images/posts/a-helpful-way-to-think-about-llms.jpeg"
---

Large Language Models (LLMs) are not external knowledge repositories; they are tools that extend your unconscious thought. Do not externalize LLMs; instead, integrate them as a part of yourself.

## Two Stages of Thought
Human thought undergoes stages of generation and verification. The emergence of ideas falls within an uncontrollable domain. An LLM acts as an external engine that accelerates this "ideation" process. It should be utilized as a catalyst to broaden the scope of your thinking.

## Treating AI Output as Your Own Thought
Do not revere LLM responses as "absolute truth." Assume, instead, that the output is an idea you have just conceived. An AIâ€™s rebuttal is your own self-doubt; its praise is your own self-satisfaction. Only when you maintain your subjectivity does the utility of the LLM as a tool become clear.

## Limitations of Probabilistic Knowledge
LLMs are the result of learning internet data through probability distributions. They are not encyclopedias that copy original data verbatim. As highlighted in the paper [Stochastic Parrots](https://dl.acm.org/doi/10.1145/3442188.3445922), the training data itself is incomplete. Every output must be subject to rigorous self-verification.

## Disparity in Data Scale
Admittedly, LLMs possess an overwhelmingly larger volume of information than any individual. They have also been trained on human preferences through Reinforcement Learning from Human Feedback (RLHF). However, the quantity of information does not inherently guarantee reliability.

## Completing the Cognitive Loop
Define the LLM as your extended unconscious. Receive more stimuli and verify them more intensely. This is the way humans think in the era of AI.

---
* [Stochastic Parrots (Bentley University)](https://dl.acm.org/doi/10.1145/3442188.3445922)
* [Thinking, Fast and Slow (Daniel Kahneman)](https://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374533555)
* [LLMs as an extension of mind (Simon Willison)](https://simonwillison.net/)
