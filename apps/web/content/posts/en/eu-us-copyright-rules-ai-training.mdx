---
title: EU and US Copyright Rules for AI Training
slug: eu-us-copyright-rules-ai-training
date: '2026-02-14'
lastReviewedAt: '2026-02-14'
locale: en
description: >-
  Overview of EU DSM TDM exceptions and US Copyright Office guidance on AI
  training, focusing on lawful access and human contribution.
tags:
  - hardware
  - llm
  - deep-dive
author: AI온다
sourceId: '975377'
sourceUrl: 'https://gall.dcinside.com/mgallery/board/view/?id=thesingularity&no=975377'
verificationScore: 0.79
alternateLocale: /ko/posts/eu-us-copyright-rules-ai-training
coverImage: /images/posts/eu-us-copyright-rules-ai-training.png
---

## TL;DR
- The EU **2019** DSM Directive includes a TDM exception in **Article 3**, and the U.S. frames training questions through **fair use** analysis.  
- These frameworks can shift leverage, costs, and compensation discussions in video and image markets.  
- Map your pipeline to “lawful access,” “where copying occurs,” and “human contribution,” then update contracts and records.  

The user-visible risk has shifted from court outcomes to pipeline choices and contract terms.  
This shift shows up across **2019**, **March 16, 2023**, and **May 9, 2025** reference points.  
The question often becomes about data conditions and value sharing.  
This focus is common in video and image workflows.  
Training data choices can affect competition and negotiating power.  

Example: A creator shares new work online, and another party produces similar-looking outputs at scale. The creator worries about lost demand, and the developer points to analysis of accessible material. The discussion then turns to access terms, opt-out signals, where copying happens, and what the output borrows.  

## Current landscape
More documents provide reference points for video and image data use debates.  
Verifiable anchors include the EU **2019** DSM Directive.  
They also include the U.S. Copyright Office guidance dated **March 16, 2023**.  
They also include the May 2025 pre-publication version of Part 3 (Generative AI Training).  

In **Article 3**, Member States provide an exception for certain TDM copying.  
It covers reproductions and extractions for TDM.  
It applies to research organizations and cultural heritage institutions.  
The purpose is “scientific research.”  
A prerequisite is “lawful access.”  
This structure combines actor, purpose, and access conditions.  
Video and image datasets are often discussed as reproduction and extraction.  
So Article 3 can serve as a reference frame.  
It can inform policy and contract design discussions.  

In the U.S., there is no single statutory TDM exception described here.  
The structure instead often relies on **fair use** analysis in disputes.  
The Copyright Office released a pre-release draft on **May 9, 2025**.  
It is **Part 3 (Generative AI Training)** of **Copyright and Artificial Intelligence**.  
It explains where reproduction can occur during training.  
It also discusses how fair use may apply.  
The Office also notes results can vary by facts.  
So it reads more like an analytical framework.  
It reads less like a safe harbor.  

“Copyright in generated outputs” is a separate axis.  
In guidance dated **March 16, 2023**, the Office summarized a human authorship principle.  
It described copyright as protecting products of “human creativity.”  
If AI determines “expressive elements,” protection may be unavailable.  
If a person selects, arranges, or modifies results creatively, registration may be possible.  
That registration would cover only the human contribution.  
So the key question becomes documentation of human control.  
It also becomes documentation of human decisions.  

## Analysis
For video and image markets, this trend often converges on sustainability questions.  
One question is whether data suppliers can keep producing.  
If training data is treated as free, incentives may weaken.  
If training is blocked broadly, negotiation costs may rise.  
That could exclude smaller developers and researchers.  
So the debate often avoids a simple allow or ban framing.  
It often becomes design of conditions and procedures.  
This is consistent with **EU Article 3 (2019)**.  
It is also consistent with **May 9, 2025** Part 3 framing.  
It is also consistent with **March 16, 2023** authorship guidance.  

Reframing the trade-offs as a decision memo:
- **If** you operate a model or service, **Then** you should not rely only on fair use under uncertainty.  
  You can decompose risk with operational controls.  
  These can include lawful access checks, licenses, and opt-out handling.  
- **If** you are a studio or creator, **Then** “stop training” alone may limit leverage.  
  You can separate permission from prohibition.  
  You can also define conditional permission in contract clauses.  
  These clauses can cover use cases, compensation, and transparency.  
- **If** you are a policy designer, **Then** you should examine opt-out operation in practice.  
  You should also consider non-litigation routes, like mediation and standard contracts.  
  The note about EU **Article 4** needs confirmation from its formal text.  

Concerns remain within this framing.  
The U.S. fair-use-centered approach can raise ex post dispute costs.  
That can create capability gaps tied to financial resources.  
The **March 16, 2023** guidance sets an authorship standard.  
More case accumulation could clarify video and image production contributions.  
This includes editing, compositing, and directing as human creativity.  

## Practical application
For developers and service operators, documentation often matters more than abstractions.  
You should document the pipeline step by step.  
Start with data inflow routes, like crawling, partners, and user uploads.  
Then document storage methods, including whether originals are retained.  
Then document preprocessing and where reproduction or extraction occurs.  
Then document rights holder request handling, like blocking and deletion.  
You should also document whether retraining occurs after removal.  
Part 3 dated **May 9, 2025** discusses where reproduction can occur.  
That focus aligns with disputes arising at specific pipeline stages.  

For creators and studios, “was my work used” can be hard to operationalize.  
The **March 16, 2023** guidance emphasizes explainable human contribution.  
You should record creative elements controlled by humans.  
If AI was used, you should keep an explainable internal account.  
It should show where human contribution ends.  
It should also show where AI contribution begins.  
This can support distribution, licensing, and claims.  
Negotiations can also become easier with separated terms.  
You can split them by use cases, scope, compensation, and notice.  

**Checklist for Today:**
- Identify each pipeline stage with reproduction or extraction, and note its lawful access basis.  
- Document which expressive elements were decided by humans versus by AI for each output.  
- Prepare a consistent procedure for rights holder requests, including deletion and exclusion handling.  

## FAQ
**Q1. Does the EU allow all AI training under the TDM exception?**  
A. This discussion supports a “scientific research” TDM exception in **DSM Directive Article 3**.  
The formal text for a general TDM exception and opt-out conditions needs confirmation.  
So there is not enough basis here to claim it allows everything.  

**Q2. In the U.S., is it over**

## Further Reading
- [Agent Performance Depends on Tools and Harness Design](/en/posts/agent-performance-tools-harness-design)
- [AI Resource Roundup (24h) - 2026-02-14](/en/posts/ai-resources-roundup-2026-02-14)
- [Beyond Rate Limits: Continuous Access Policy Engine Design](/en/posts/beyond-rate-limits-continuous-access-policy-engine-design)
- [Decomposing AI Risks: Tasks, Transparency, And Safety Testing](/en/posts/decomposing-ai-risks-tasks-transparency-safety-testing)
- [Designing Agent Defenses Against Prompt Injection Attacks](/en/posts/designing-agent-defenses-against-prompt-injection-attacks)
---

## References

- [Directive (EU) 2019/790 (EUR-Lex) - Article 3 Text and data mining for the purposes of scientific research - eur-lex.europa.eu](https://eur-lex.europa.eu/legal-content/EN/AUTO/?toc=OJ%3AL%3A2019%3A130%3ATOC&uri=uriserv%3AOJ.L_.2019.130.01.0092.01.ENG)
- [Copyright and Artificial Intelligence | U.S. Copyright Office - copyright.gov](https://www.copyright.gov/ai/)
- [U.S. Copyright Office - Copyright and Artificial Intelligence, Part 3: Generative AI Training (May 2025, pre-publication PDF) - copyright.gov](https://www.copyright.gov/ai/Copyright-and-Artificial-Intelligence-Part-3-Generative-AI-Training-Report-Pre-Publication-Version.pdf)
- [Copyright Registration Guidance: Works Containing Material Generated by Artificial Intelligence (U.S. Copyright Office, Published March 16, 2023) - copyright.gov](https://www.copyright.gov/ai/ai_policy_guidance.pdf)
- [Generative Artificial Intelligence and Copyright Law (Congressional Research Service Legal Sidebar) - congress.gov](https://www.congress.gov/crs-product/LSB10922)
