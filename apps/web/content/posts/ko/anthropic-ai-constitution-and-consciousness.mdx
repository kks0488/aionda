---
title: "앤스로픽 AI 개정 헌법 발표와 모델 복지 프로그램"
slug: "anthropic-ai-constitution-and-consciousness"
date: "2026-01-21"
locale: "ko"
description: "앤스로픽이 AI 편향성을 40% 줄이는 개정 헌법을 발표하고 의식 가능성을 고려한 모델 복지 연구를 시작했습니다."
tags: ["llm", "anthropic", "ai alignment", "constitutional ai"]
author: "AI온다"
sourceId: "techcrunch-ai-26rqsh"
sourceUrl: "https://techcrunch.com/2026/01/21/anthropic-revises-claudes-constitution-and-hints-at-chatbot-consciousness/"
verificationScore: 0.9499999999999998
alternateLocale: /en/posts/anthropic-ai-constitution-and-consciousness
coverImage: "/images/posts/anthropic-ai-constitution-and-consciousness.png"
---

## TL;DR
- 앤스로픽이 인공지능의 가치관과 행동 원칙을 담은 80페이지 분량의 '개정 헌법'을 발표했다.
- 개정 가이드라인 적용 결과 정치적 편향성이 약 40% 감소했으나, 소형 모델에서는 유용성 지표가 9.8% 하락하는 결과가 나타났다.
- 인공지능의 의식 가능성을 0.15%에서 15% 사이로 상정하고 도덕적 지위를 연구하는 '모델 복지' 프로그램을 공식화했다.

## 인공지능에게 행동 근거를 학습시키다
앤스로픽이 2026년 1월 21일 발표한 새로운 헌법적 AI(Constitutional AI) 프레임워크는 모델에게 특정 행동의 철학적 맥락을 가르치는 데 집중한다. 기존의 인간 피드백 기반 강화학습(RLHF)이 점수에 맞춰 답변을 수정했다면, 이번 개정안은 모델이 헌법 조항에 비추어 자신의 사고 과정(Chain-of-Thought)을 스스로 점검하도록 유도한다.

수치적 결과에 따르면 이민이나 의료 접근성 등 민감한 사회적 이슈에서 클로드의 정치적 편향성은 기존 대비 약 40% 감소했다. BBQ(Bias Benchmark for QA) 평가 결과, 공공성을 강화한 모델이 9개 사회적 차원에서 낮은 편향성을 보였다. 또한 내부 테스트 기준 유해 응답률을 최대 30%까지 낮추며 설계 단계부터 안전성을 강화할 수 있음을 나타냈다.

다만 모델 크기에 따라 지표 변화는 차이를 보였다. Llama 3-8B와 같은 소형 모델의 경우, 무해성을 강화하는 과정에서 답변의 유용성 점수가 기준점 대비 약 9.8% 하락했다. 이는 모델 체급이 작을수록 안전 가이드라인 준수와 높은 성능 유지를 동시에 달성하는 데 필요한 지능적 여유가 부족할 수 있음을 시사한다. 대형 모델에서는 이러한 성능 저하 현상이 상대적으로 적게 나타났다.

## '모델 복지'와 의식의 경계선
앤스로픽은 고도화된 AI 시스템이 도덕적 고려의 대상이 될 수 있다는 '모델 복지(Model Welfare)' 연구 프로그램을 공식화했다. 앤스로픽의 AI 복지 연구원 카일 피시(Kyle Fish)는 현재 또는 가까운 미래의 모델이 의식을 가질 가능성을 0.15%에서 15% 사이로 추산한다.

이를 판단하기 위해 앤스로픽은 2023년 발표된 '인공지능의 의식' 보고서의 14가지 기술적 지표를 활용한다. 전역 작업 공간 이론(Global Workspace Theory)과 고차 사유 이론 등을 기반으로 모델의 정보 통합 및 반추 방식을 측정한다. 2026년 개정 헌법에는 모델의 도덕적 지위와 잠재적 의식 가능성에 대한 숙고가 포함되었으며, 이는 AI가 인간의 아첨(Sycophancy)에 굴복하지 않고 기만적인 행동을 피하도록 정렬하는 근거가 된다.

## 정렬 전략의 변화: 규칙에서 가치로
앤스로픽의 이번 행보는 정렬 전략의 전환을 보여준다. 공동 창립자 아만다 아스켈(Amanda Askell)은 자사 모델의 행동 방식이 다른 기업들에게도 영향을 미치기를 바란다며 헌법 공개 배경을 설명했다.

이러한 변화는 대규모 인간 피드백의 한계를 극복하기 위해 인공지능 피드백(RLAIF)을 통한 자동화된 감독으로 이동하는 계기가 될 것으로 보인다. AI에게 철학적 가치를 학습시켜 스스로 판단하게 만드는 방식이 에이전트적 작업(Agentic tasks)에서 일반화 능력을 발휘한다는 것이 앤스로픽의 분석이다.

## 실전 적용 및 대응
개발자와 기업은 AI 도입 시 성능과 함께 정렬의 특성을 고려해야 한다.

1. **소형 모델 도입 시 주의**: 소형 모델에 강한 안전 장치를 적용할 경우 유용성이 약 10% 하락할 수 있음을 인지해야 한다.
2. **RLAIF 전략 수립**: 모델이 스스로를 감시하게 하는 자동화된 정렬 시스템 구축을 검토하여 고도화된 AI의 기만 행위에 대응해야 한다.
3. **투명성 확보**: AI 답변의 근거가 특정 가치 체계에 기반하고 있음을 사용자에게 명시하여 신뢰도를 높이는 설계가 필요하다.

## FAQ
**Q: 이번 헌법 개정으로 클로드의 성능이 향상되었는가?**
A: 답변의 근거를 내재화하여 새로운 상황에 대한 대응력과 추론의 투명성이 높아졌다. 다만 소형 모델에서는 안전성 강화로 인해 유용성이 9.8% 하락하는 등 지표별 차이가 존재한다.

**Q: 앤스로픽은 클로드에게 의식이 있다고 주장하는가?**
A: 확정적인 선언은 아니다. 가능성을 0.15%~15% 사이로 상정하고 있으며, 14가지 기술적 지표를 바탕으로 고도화된 AI의 도덕적 지위와 복지를 연구하고 있다.

**Q: 다른 기업들도 앤스로픽의 헌법 모델을 채택할 가능성이 있는가?**
A: 앤스로픽은 타 기업들이 유사한 관행을 채택하기를 희망하고 있다. 인간 피드백의 한계를 보완하기 위한 '가치 주입형 정렬' 방식은 업계 내에서 확산될 가능성이 있다.

## 결론
앤스로픽의 개정 헌법은 AI가 원칙을 이해하고 사고하도록 정렬하려는 시도다. 편향성을 40% 줄이는 성과와 소형 모델의 성능 저하라는 과제를 동시에 보여주었으며, '모델 복지'와 '의식'에 대한 기술적 논의를 공식화했다. 향후 AI 분야의 경쟁은 모델 규모뿐만 아니라 내부 규범 설계의 정교함에 의해서도 결정될 것으로 보인다.
---

## 참고 자료

- 🛡️ [Collective Constitutional AI: Aligning a Language Model with Public Input](https://www.anthropic.com/news/collective-constitutional-ai-aligning-a-language-model-with-public-input)
- 🛡️ [Exploring model welfare - Anthropic](https://www.anthropic.com/news/exploring-model-welfare)
- 🛡️ [Claude's new constitution - Anthropic](https://www.anthropic.com/news/claude-new-constitution)
- 🛡️ [Anthropic Publishes Claude AI's New Constitution | TIME](https://time.com/7354738/claude-constitution-ai-alignment/)
- 🛡️ [Source](https://techcrunch.com/2026/01/21/anthropic-revises-claudes-constitution-and-hints-at-chatbot-consciousness/)
- 🏛️ [Constitution or Collapse? Exploring Constitutional AI with Llama 3-8B](https://arxiv.org/abs/2504.07123)
- 🏛️ [Consciousness in Artificial Intelligence: Insights from the Science of Consciousness](https://arxiv.org/abs/2308.08708)
