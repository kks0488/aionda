---
title: '생성형 비디오, 학습에서 유통으로 번진 저작권 분쟁'
slug: ai-video-copyright-disputes-shift-from-training-to-distribution
date: '2026-02-16'
lastReviewedAt: '2026-02-16'
locale: ko
description: Seedance 2.0 논란은 저작권 쟁점이 학습에서 결과물 생성·유통 단계로 이동했음을 보여준다.
tags:
  - llm
  - deep-dive
author: AI온다
sourceId: techcrunch-ai-a51f701c56035f4c
sourceUrl: >-
  https://techcrunch.com/2026/02/15/hollywood-isnt-happy-about-the-new-seedance-2-0-video-generator/
verificationScore: 0.7666666666666666
alternateLocale: /en/posts/ai-video-copyright-disputes-shift-from-training-to-distribution
coverImage: >-
  /images/posts/ai-video-copyright-disputes-shift-from-training-to-distribution.png
---

## 세 줄 요약

- **무슨 변화/핵심이슈인가?** Seedance 2.0 관련 반발은 생성형 비디오 저작권 충돌의 초점이 **학습 단계**에서 **결과물 생성·유통 단계**로 옮겨가고 있음을 보여준다.  
- **왜 중요한가?** 침해로 보이는 영상이 확산되면 권리자는 피해를 주장할 수 있고, 모델·플랫폼은 **DMCA(17 U.S. Code § 512)** 같은 중개자 프레임 안에서 **삭제·차단·안전장치** 요구를 동시에 받는다.  
- **독자는 뭘 하면 되나?** 비디오 생성/유통 파이프라인을 **입력(프롬프트)–출력(결과물)–배포(업로드/재배포)** 3구간으로 나누고, 각 구간의 기록·차단·고지 책임을 문서로 확정한다.

짧은 싸움 장면 하나가 논란을 키웠다. **AP**는 **Tom Cruise**와 **Brad Pitt**가 등장하는 형태의 생성 영상이 문제 제기의 촉발점 중 하나였다고 전했다. 텍스트 몇 줄로 유명 배우 얼굴을 한 인물이 등장하고, 영상은 ‘바이럴’이라는 이름으로 빠르게 퍼진다. 할리우드 단체들은 이 흐름이 더는 “실험” 수준이 아니라, 저작권 침해로 이어질 수 있는 워크플로로 굳어지고 있다고 본다. TechCrunch가 전한 요지는, Hollywood 조직들이 AI 비디오 모델 **Seedance 2.0**이 “blatant” 저작권 침해 도구로 쓰인다고 반발한다는 것이다.

예: 한 제작사가 홍보용 짧은 영상을 올렸는데, 곧바로 닮은꼴 영상이 따라붙는다. 사람들은 재미로 공유하지만, 권리자는 문제를 제기한다. 담당자는 삭제 요청과 서비스 운영 사이에서 결정을 미룬다.

이 사건이 중요한 이유는 ‘학습 데이터’ 논쟁만으로는 설명이 부족해졌기 때문이다. 전선은 **출력물(생성)과 배포(유통)**로 이동했다. 누가 막아야 하는가—모델 제공사인가, 플랫폼인가, 아니면 둘 다인가.

## 현황

논점은 “훈련 데이터에 무엇이 들어갔는가”에서 “**지금 만들어져 퍼지는 결과물**”로 옮겨가고 있다. TechCrunch 인용에 따르면 할리우드 조직들은 Seedance 2.0이 “blatant” 저작권 침해에 쓰인다고 주장했다. 또한 AP와 The Verge 보도를 종합하면, 문제 제기는 훈련 데이터보다 **결과물의 생성·확산**에 더 초점이 맞춰져 있다. AP는 **Tom Cruise**와 **Brad Pitt**가 등장하는 싸움 장면 형태의 Seedance 2.0 생성 영상이 논란의 촉발점 중 하나였다고 전했다.

The Verge에 따르면, **Disney**는 Seedance 2.0이 자사 보호 캐릭터를 “hijacking”했다고 비판했다. The Verge는 그 결과물이 캐릭터를 **reproducing(복제), distributing(배포), creating derivative works(2차적저작물 생성)** 하는 형태로 나타난다는 주장도 함께 전했다. 즉 쟁점은 “비슷하게 만들었다”에 그치지 않고, 권리자가 보기에 ‘권리 행사의 영역’과 맞닿는 사용이 생산·유통된다는 문제 제기다.

한편 **ByteDance**는 AP 보도에서 지식재산권을 존중하며 무단 사용을 막기 위한 **safeguards(안전장치)**를 개선하겠다고 말했다. 다만, 이번 인용 범위만으로는 (1) Seedance 2.0 훈련 데이터의 출처, (2) 라이선스 체계, (3) 어떤 안전장치를 어떤 수준으로 제공하는지까지는 구체적으로 확정하기 어렵다. 이 공백이 다음 공방의 쟁점이 될 수 있다.

## 분석

이번 케이스가 던지는 신호는 비교적 단순하다. 생성형 비디오 저작권 분쟁은 “학습 데이터의 합법성”이라는 한 가지 질문에서, “**생성-편집-업로드-확산** 전체 흐름을 누가 통제하느냐”로 확장되고 있다. 이 흐름에서 모델 제공사는 프롬프트 필터링, 특정 IP/인물 재현 방지 같은 안전장치 요구를 받기 쉽다. 플랫폼은 **DMCA(17 U.S. Code § 512)** 체계에서 신고가 들어오면 접근 차단·삭제 같은 조치를 운영하라는 압박을 받을 수 있다. 다만 어느 쪽도 전면적인 감시나 차단을 손쉽게 약속하기는 어렵다.

트레이드오프는 다음처럼 정리된다.  
- **강한 필터링**은 권리자 리스크를 줄일 수 있지만, 합법적 패러디·비평·창작까지 막을 가능성이 있다.  
- **느슨한 필터링**은 사용자 경험을 해치지 않을 수 있지만, 침해로 보이는 결과물이 확산될 때 “안전장치가 작동했는가”라는 비판에 취약해질 수 있다.  
- **워터마킹/출처증명** 같은 투명성 장치는 보완책이 될 수 있지만, The Verge는 **C2PA 메타데이터가 소셜 플랫폼에서 stripped(제거)** 되는 경우가 잦다고 지적했다. 즉 “붙이는 것”만으로는 부족하고, 유통 단계에서 보존·표시·집행이 함께 설계돼야 한다. 또한 NIST는 워터마킹·라벨링·감사 등 접근법의 스펙트럼을 정리하지만, 단일 기술만으로 해결된다고 단정하지는 않는다.

또 하나의 축은 규제·정책 환경이다. EU의 **DSA( Regulation (EU) 2022/2065 )**는 ‘일반적 모니터링 의무’ 금지를 명시하는 방향을 담고 있다. 한편 AP는 **AI 생성 영상·오디오에 디지털 워터마크나 메타데이터를 요구**하고, 플랫폼에 **사용자 고지 의무**를 부과하는 취지의 초당적 법안 흐름을 보도했다. 정리하면 정책은 “전면 감시”로만 가기 어렵고, “표시·추적·사후 집행”을 조합하는 방향으로 논의가 진행될 수 있다. 다만 법제화 여부와 최종 요건은 별도 확인이 필요하다.

## 실전 적용

의사결정은 “우리 서비스가 어디에 서 있나”부터 시작한다. 모델을 직접 제공하는가, 아니면 생성된 영상을 호스팅/추천하는가. 둘 다라면 책임도 겹친다. 이때 설계 단위는 **3단 분리**가 유용하다: 입력(프롬프트) → 출력(렌더링 결과물) → 배포(업로드/공유/추천). 구간마다 실패 모드가 다르므로, 하나의 필터로 모두 해결하려 하면 비용이 늘고 책임소재도 흐려질 수 있다.

예: 어떤 팀이 생성 비디오 기능을 붙였더니, 사용자들이 특정 스타일을 흉내 낸 영상을 만들기 시작한다. 처음엔 장난처럼 보이지만, 공유가 늘면서 권리자 신고가 들어온다. 팀은 “막을지, 표시할지, 남길지”를 두고 내부에서 충돌한다. 이때 필요한 것은 구간별 규칙과 로그, 그리고 차단 기준의 문서화다.

**오늘 바로 할 일:**  
- 프롬프트/업로드 단계에서 “특정 인물·캐릭터 재현” 신고가 들어왔을 때의 차단 기준과 예외 처리 원칙을 한 문서로 정리한다.  
- 워터마킹·메타데이터(C2PA 등)를 쓴다면, 업로드·재인코딩 과정에서 메타데이터가 제거될 가능성을 전제로 표시 실패 시 대응 절차를 포함해 설계한다.  
- **DMCA(17 U.S. Code § 512)** 관점에서 삭제/차단 처리 흐름과 반복 침해자 대응 정책이 운영 가능한 수준인지 점검하고, 부족한 부분은 추가 확인 항목으로 남긴다.

## FAQ

**Q1. Seedance 2.0 논란의 핵심은 훈련 데이터 무단 사용인가, 결과물 침해인가?**  
A. 이번 인용 범위에서 확인되는 비판의 중심은 **결과물의 생성과 유통**, 그리고 이를 막을 **의미 있는 안전장치 부재**에 더 가깝다. 훈련 데이터의 구체 출처·라이선스는 이번 조사 결과만으로 확정하기 어렵다.

**Q2. 책임은 모델 제공사와 플랫폼 중 누가 더 크게 지게 되나?**  
A. 현재 보이는 프레임에서는 둘 다 압박을 받는다. 모델 제공사는 침해 방지 안전장치 강화를 요구받고, 플랫폼은 **DMCA(17 U.S. Code § 512)** 체계 아래에서 접근 차단/삭제 같은 조치 프로세스를 요구받는다. 다만 워터마킹·로그 보관 같은 의무의 법적 귀속은 관할과 법제에 따라 달라질 수 있어 추가 확인이 필요하다.

**Q3. 워터마킹이나 출처 증명은 실효성이 있나?**  
A. 도움이 될 수 있으나 한계도 있다. The Verge는 **C2PA 메타데이터가 소셜 미디어에서 제거되기 쉽다**고 지적했다. 따라서 기술 적용만으로 충분하다고 보기 어렵고, 유통 플랫폼의 보존·표시·집행 설계가 함께 필요하다.

## 결론

Seedance 2.0을 둘러싼 할리우드의 반발은 생성형 비디오 저작권 분쟁의 중심이 ‘학습’에서 ‘출력과 배포’로 이동하고 있음을 보여준다. 다음 관전 포인트는 단일 기술이 아니라, 모델 제공사와 플랫폼이 **안전장치·표시·집행**을 어떤 조합으로 나눠 책임질지다. 동시에 그 조합이 창작 자유와 권리 보호 사이에서 어떤 균형을 택하는지도 쟁점이 된다.

## 다음으로 읽기
- [AI 자료 모음 (24h) - 2026-02-16](/ko/posts/ai-resources-roundup-2026-02-16)
- [에이전트 실행 루프, 자가구현의 대가](/ko/posts/building-reliable-agent-loops-without-framework-dependencies)
- [관계시험 프롬프트와 AI 경계 설정](/ko/posts/designing-boundaries-for-relationship-tests-in-ai-chats)
- [장기기억·지속학습·재귀개선 설계](/ko/posts/designing-memory-continual-learning-recursive-improvement-systems)
- [AI 코딩 도구, 확장·권한이 성패 가른다](/ko/posts/choosing-ai-coding-tools-extensions-permissions-operations)
---

## 참고 자료

- [Hollywood groups condemn ByteDance’s AI video generator, claiming copyright infringement - apnews.com](https://apnews.com/article/ai-seedance-bytedance-hollywood-copyright-7e445388401d172c6bf51d0d42aa4f24)
- [After spooking Hollywood, ByteDance will tweak safeguards on new AI model (The Verge) - theverge.com](https://www.theverge.com/ai-artificial-intelligence/879644/bytedance-seedance-safeguards-ai-video-copyright-infringement)
- [Hollywood groups condemn ByteDance's AI video generator, claiming copyright infringement (AP News) - apnews.com](https://apnews.com/article/7e445388401d172c6bf51d0d42aa4f24)
- [17 U.S. Code § 512 - Limitations on liability relating to material online (DMCA) - law.cornell.edu](https://www.law.cornell.edu/uscode/text/17/512)
- [Regulation (EU) 2022/2065 (Digital Services Act) — Official Journal text - eur-lex.europa.eu](https://eur-lex.europa.eu/eli/reg/2022/2065/oj/eng)
- [New bipartisan bill would require online identification, labeling of AI-generated videos and audio - apnews.com](https://apnews.com/article/7026e6223c64a042bd434b11c211b753)
- [Sora is showing us how broken deepfake detection is (The Verge) - theverge.com](https://www.theverge.com/report/806359/openai-sora-deepfake-detection-c2pa-content-credentials)
- [Reducing Risks Posed by Synthetic Content: An Overview of Technical Approaches to Digital Content Transparency (NIST) - nist.gov](https://www.nist.gov/publications/reducing-risks-posed-synthetic-content-overview-technical-approaches-digital-content)
- [techcrunch.com - techcrunch.com](https://techcrunch.com/2026/02/15/hollywood-isnt-happy-about-the-new-seedance-2-0-video-generator/)
