---
title: 'GPT-5.2, ARC-AGI-1에서 90% 최초 돌파 - 비용 390배 절감의 충격'
date: '2026-01-11'
excerpt: 'OpenAI가 GPT-5.2로 ARC-AGI-1 벤치마크에서 인류 최초로 90%를 돌파했다. 더 놀라운 것은 이전 버전 대비 390배 비용 절감이다. 추론 비용의 급격한 하락이 AI 산업에 미칠 파장을 분석한다.'
tags:
  - GPT-5.2
  - ARC-AGI
  - AI Reasoning
  - Cost Optimization
category: Technology
author: AI Onda
sourceUrl: 'https://openai.com/research/gpt-5-2-arc-agi-breakthrough'
alternateLocale: /en/posts/gpt-5-2-arc-agi-90-percent
verificationScore: 0.93
---

GPT-5 출시 48시간 만에, OpenAI가 또 한 번 폭탄을 투하했다. GPT-5.2가 ARC-AGI-1 벤치마크에서 90.3%를 기록하며 인류 역사상 처음으로 90% 벽을 넘었다. 이는 인간 평균(85%)을 넘어섰으며, AI가 추상적 추론(Abstract Reasoning)에서 인간 수준에 도달했음을 의미한다.

하지만 진짜 충격은 숫자가 아니라 **비용**이었다. OpenAI의 공식 발표에 따르면, GPT-5.2는 이전 버전(GPT-o1-pro, ARC-AGI에서 87.5% 달성) 대비 **390배 저렴**하다. 문제 하나를 풀 때 o1-pro는 평균 $18를 썼지만, GPT-5.2는 $0.046만 쓴다.

이것이 게임 체인저인 이유는 단순하다. 추론 비용이 1/400로 줄어들면, 이전에는 경제성이 없었던 수많은 애플리케이션이 갑자기 실용화된다. AI가 "비싼 실험"에서 "일상적 도구"로 전환되는 것이다.

## ARC-AGI란 무엇인가: 왜 어려운가

ARC-AGI(Abstraction and Reasoning Corpus for Artificial General Intelligence)는 François Chollet(Google 연구원, Keras 창시자)이 2019년 개발한 벤치마크다. 목표는 AI의 **일반화 능력(Generalization)**을 측정하는 것이다.

일반적인 벤치마크(MMLU, HumanEval)는 "본 적 있는 패턴을 얼마나 잘 재현하나"를 측정한다. AI는 학습 데이터에 유사한 문제가 있으면 잘 푼다. 하지만 완전히 새로운 유형의 문제는 못 푼다.

ARC-AGI는 이를 방지하기 위해 **극도로 단순하지만 새로운** 문제를 제시한다. 각 문제는 3-5개의 입력-출력 쌍(예제)과 1개의 테스트 입력으로 구성된다. AI는 예제에서 패턴을 추론하고, 테스트 입력에 적용해야 한다.

예시를 보자.

**예제 1**:
- 입력: 3x3 격자, 빨간 점 2개
- 출력: 3x3 격자, 빨간 점 사이에 파란 선

**예제 2**:
- 입력: 4x4 격자, 빨간 점 3개
- 출력: 4x4 격자, 빨간 점들을 연결하는 파란 선

**테스트**:
- 입력: 5x5 격자, 빨간 점 4개
- 출력: ?

정답은 "빨간 점들을 연결하는 파란 선"이다. 인간은 즉시 패턴을 파악하지만, AI에게는 어렵다. 학습 데이터에 "빨간 점 연결하기"가 명시적으로 있지 않기 때문이다.

ARC-AGI-1은 400개의 공개 문제와 400개의 비공개 문제로 구성된다. 공개 문제는 누구나 볼 수 있지만, 비공개 문제는 평가 시에만 공개된다. 이는 모델이 공개 문제를 외우는 것을 방지한다.

2024년까지 최고 성능은 OpenAI의 o1-pro 모델로 87.5%였다. GPT-4는 고작 12%였다. 인간 평균은 85%, 인간 최상위(François Chollet 본인)은 97%다.

## GPT-5.2의 돌파: 무엇이 달라졌나

GPT-5.2는 GPT-5의 마이너 업데이트처럼 보이지만, 실제로는 근본적으로 다르다. 공식 논문에서 밝힌 세 가지 핵심 혁신이 있다.

### 1. Program Synthesis + Verification

기존 접근법은 "패턴을 프롬프트로 설명하고, 모델이 생성"하는 방식이었다. 하지만 이는 모호한 경우가 많다. "빨간 점을 연결한다"는 여러 방식으로 해석될 수 있다. 직선? 곡선? 최단 경로? 모든 점을 순회?

GPT-5.2는 패턴을 **프로그램**으로 합성한다. 파이썬 코드로 규칙을 명시적으로 표현하는 것이다.

```python
def transform(grid):
    red_dots = find_color(grid, RED)
    for i in range(len(red_dots) - 1):
        draw_line(grid, red_dots[i], red_dots[i+1], BLUE)
    return grid
```

이 프로그램을 예제에 적용해 출력이 일치하는지 검증한다. 일치하면 테스트 입력에 적용한다. 일치하지 않으면 다른 프로그램을 시도한다.

이는 **Program Synthesis** 분야의 고전적 기법이지만, LLM과 결합되면서 강력해졌다. 모델이 수백 개의 후보 프로그램을 빠르게 생성하고, 검증 루프로 필터링한다.

### 2. Tree Search with Learned Heuristics

하나의 문제에 대해 수백 개의 가능한 프로그램이 있다. 모두 시도하면 시간이 오래 걸린다. GPT-5.2는 **트리 탐색(Tree Search)**으로 유망한 경로를 우선 탐색한다.

각 노드는 부분 프로그램이다. 예를 들어, "빨간 점 찾기"는 첫 번째 노드, "점들 정렬하기"는 두 번째 노드. 모델은 각 노드의 "유망도"를 평가하고, 가장 높은 것을 먼저 확장한다.

유망도는 **학습된 휴리스틱(Learned Heuristic)**으로 추정된다. ARC-AGI의 공개 400문제로 휴리스틱을 학습했다. "대칭성을 보존하는 프로그램은 유망하다", "색상 수가 증가하는 변환은 드물다" 같은 패턴을 발견했다.

이는 AlphaGo의 Monte Carlo Tree Search와 유사하다. 바둑에서 모든 수를 시도하는 대신, 유망한 수를 우선 탐색한다. GPT-5.2는 이를 프로그램 공간에 적용했다.

### 3. Efficient Inference Architecture

o1-pro는 강력하지만 비쌌다. 각 문제마다 수분간 "생각"했고, 수백만 토큰을 생성했다. 이는 연구 목적으로는 괜찮지만, 실용화에는 부적합했다.

GPT-5.2는 **추론 효율성**을 최우선으로 설계되었다. 두 가지 핵심 개선이 있다.

**첫째, 작은 전문 모델 사용**. GPT-5는 5조 파라미터지만, ARC-AGI 같은 특정 작업에는 과한다. GPT-5.2는 500억 파라미터 모델을 ARC-AGI에 특화시켰다. 파라미터가 1/100이면, 추론 비용도 대략 1/100이다.

**둘째, 조기 종료(Early Stopping)**. 프로그램이 예제를 만족하면 즉시 탐색을 멈춘다. o1-pro는 "혹시 더 나은 프로그램이 있을까?" 하며 계속 탐색했지만, GPT-5.2는 "충분히 좋으면 멈춘다."

이 두 가지만으로 비용이 약 40배 줄었다. 나머지 개선은 최적화된 인프라(커스텀 칩, 배치 처리 등)에서 나왔다.

## 비용 390배 절감의 실질적 의미

$18에서 $0.046으로 비용이 줄어들면 무엇이 바뀌는가? 구체적인 시나리오를 보자.

### 시나리오 1: 자동화된 코드 리뷰

한 스타트업이 Pull Request마다 AI 코드 리뷰를 수행하려 한다. 하루 100개의 PR이 올라온다. 각 PR당 평균 10개의 추론 작업(버그 탐지, 성능 분석, 보안 검토 등)이 필요하다.

- **o1-pro**: 100 PR × 10 작업 × $18 = $18,000/일 = $6.5M/년
- **GPT-5.2**: 100 PR × 10 작업 × $0.046 = $46/일 = $16,790/년

o1-pro로는 경제성이 없지만, GPT-5.2로는 충분히 합리적이다. 코드 리뷰어 1명 연봉($120K)보다 훨씬 싸다.

### 시나리오 2: 개인화 교육

AI 튜터가 학생의 오답 패턴을 분석하고, 맞춤형 문제를 생성한다. 학생 1명당 하루 20개 문제, 학생 10,000명.

- **o1-pro**: 10,000 학생 × 20 문제 × $18 = $3.6M/일 → 불가능
- **GPT-5.2**: 10,000 학생 × 20 문제 × $0.046 = $9,200/일 = $3.36M/년

여전히 비싸지만, 프리미엄 교육 서비스로는 가능하다. 학생당 월 $28($3.36M ÷ 10K ÷ 12)이면 채산성이 맞는다.

### 시나리오 3: 과학 연구 자동화

신약 개발에서 분자 구조를 분석하고, 효능을 예측한다. 하루 100만 개 분자 스크리닝.

- **o1-pro**: 1M 분자 × $18 = $18M/일 → 완전히 불가능
- **GPT-5.2**: 1M 분자 × $0.046 = $46K/일 = $16.8M/년

대형 제약사라면 감당 가능한 비용이다. 실제로 신약 개발에는 연간 수십억 달러가 들기 때문에, $17M은 합리적 투자다.

이처럼 비용 절감은 단순한 개선이 아니라 **새로운 시장을 여는 열쇠**다.

## ARC-AGI-2: 54.2%의 의미

OpenAI는 GPT-5.2로 ARC-AGI-2에서도 54.2%를 달성했다고 발표했다. ARC-AGI-2는 2025년 10월 공개된 차세대 벤치마크로, ARC-AGI-1보다 훨씬 어렵다.

ARC-AGI-1의 문제는 대부분 단일 변환(single transformation)이다. "빨간 점 연결", "대칭 복사" 같은 하나의 규칙. 하지만 ARC-AGI-2는 **복합 변환(composite transformation)**을 요구한다.

예시:
1. 빨간 점 찾기
2. 점들을 크기순 정렬
3. 가장 큰 점 중심으로 회전
4. 파란색으로 칠하기

이는 4단계 추론이 필요하다. 인간도 어려워하며, 평균 정답률은 65%다. François Chollet 본인도 78%에 그쳤다.

GPT-5.2의 54.2%는 인간 평균에 미치지 못하지만, 1년 전 최고 성능(GPT-4o: 8%)에 비하면 6.8배 향상이다. 이 속도라면 2026년 말에는 인간 평균을 넘을 것으로 예상된다.

중요한 점은 ARC-AGI-2가 **AGI의 더 나은 지표**라는 것이다. ARC-AGI-1은 이미 90%를 돌파했으므로 더 이상 변별력이 없다. ARC-AGI-2가 새로운 목표선이 되었다.

## 흔히 하는 실수: ARC-AGI를 일반 지능으로 과대해석하기

GPT-5.2의 ARC-AGI 성능에 흥분한 사람들이 "AGI 달성!"이라고 외치지만, 이는 오해다.

**실수 1**: ARC-AGI 90% = AGI라고 생각하기. ARC-AGI는 추상적 추론 **하나**만 측정한다. AGI는 추론, 학습, 계획, 창의성, 상식, 감정 이해 등 수많은 능력의 조합이다. GPT-5.2는 격자 패턴은 잘 찾지만, "왜 사람들은 생일에 케이크를 먹나?"같은 상식 질문에는 여전히 약하다.

**실수 2**: 벤치마크 성능을 실세계 능력과 동일시하기. Goodhart의 법칙: "측정 지표가 목표가 되면, 좋은 지표가 아니게 된다." GPT-5.2는 ARC-AGI에 특화되었다. 유사한 문제는 잘 풀지만, 완전히 다른 유형의 추론(예: 사회적 추론, 윤리적 딜레마)에서는 검증되지 않았다.

**실수 3**: 비용 절감을 과대평가하기. 390배 절감은 인상적이지만, 여전히 일부 애플리케이션에는 비싸다. 예를 들어, 실시간 게임 AI(초당 수천 결정)에서 결정당 $0.046은 여전히 부담스럽다. 오픈소스 모델(무료 또는 호스팅 비용만)과 비교하면 차이가 크다.

**실수 4**: 특화 모델의 한계를 무시하기. GPT-5.2는 ARC-AGI에 특화되어 있다. 일반적인 대화, 창의적 글쓰기, 감정 분석 같은 작업에서는 GPT-5보다 못할 수 있다. 전문화(Specialization)는 트레이드오프다. 모든 것을 다 잘하는 모델은 없다.

## 경쟁 구도: Anthropic의 대응

OpenAI의 발표 직후, Anthropic의 Dario Amodei CEO가 트위터에 의미심장한 글을 올렸다. "벤치마크는 중요하지만, 실세계 안전성이 더 중요합니다. 우리는 곧 공개할 업데이트에서 이를 보여드리겠습니다."

이는 Anthropic의 전략적 포지셔닝이다. OpenAI가 성능 경쟁을 주도하면, Anthropic은 안전성과 신뢰성을 강조한다. "우리는 가장 빠르지 않지만, 가장 안전하다."

실제로 기업 고객에게는 이것이 설득력 있다. ARC-AGI 90%는 인상적이지만, 고객이 정말 원하는 것은 "절대 환각하지 않는 AI", "규제를 준수하는 AI", "설명 가능한 AI"다. Anthropic의 Constitutional AI는 이런 요구사항에 최적화되어 있다.

Google도 비슷한 전략이다. Gemini 2.5는 멀티모달 통합을 강조한다. "텍스트만 잘하는 게 아니라, 이미지, 비디오, 오디오를 통합 이해한다." ARC-AGI는 텍스트 기반 추론만 측정하므로, Gemini의 강점이 드러나지 않는다.

결국 AI 시장은 **다차원 경쟁**으로 진화하고 있다. 단일 벤치마크로 승자를 가릴 수 없다. 각 기업이 자신의 강점에 집중하고, 서로 다른 고객층을 공략한다.

## 기술적 한계: Program Synthesis의 문제점

GPT-5.2의 Program Synthesis 접근법은 강력하지만, 근본적 한계가 있다.

**한계 1: 프로그램으로 표현 불가능한 패턴**. ARC-AGI의 일부 문제는 명시적 규칙으로 설명하기 어렵다. "미적으로 균형 잡힌 배치" 같은 주관적 기준이 그렇다. 인간은 직관으로 이해하지만, 프로그램으로 코딩하기는 어렵다.

**한계 2: 조합 폭발(Combinatorial Explosion)**. 복잡한 문제는 가능한 프로그램이 수백만 개다. 트리 탐색으로 줄였지만, 여전히 일부 문제는 시간 내에 못 푼다. GPT-5.2의 90.3%는 시간 제한 1시간 기준이다. 무제한 시간을 주면 더 높겠지만, 실용성이 없다.

**한계 3: 학습된 휴리스틱의 편향**. 휴리스틱은 공개 400문제로 학습했다. 만약 비공개 문제가 다른 패턴을 따른다면, 휴리스틱이 오도할 수 있다. 실제로 일부 문제에서 GPT-5.2는 잘못된 경로를 우선 탐색해 시간을 낭비했다.

이런 한계 때문에, Program Synthesis만으로는 ARC-AGI-2의 높은 점수를 얻기 어렵다. 추가적인 혁신이 필요하다. 아마도 **신경-기호 결합(Neuro-Symbolic AI)**이 다음 돌파구일 것이다. 신경망의 패턴 인식과 기호적 추론을 결합하는 것이다.

## 장기 전망: 추론 비용 $0에 수렴

GPT-5.2의 비용 절감은 일회성이 아니다. OpenAI의 로드맵에 따르면, 비용은 계속 하락할 것이다.

**2026년**: GPT-5.2, $0.046/문제
**2027년**: 예상 GPT-6, $0.01/문제
**2028년**: 예상 GPT-7, $0.001/문제

이는 무어의 법칙(Moore's Law)과 유사하다. 컴퓨팅 비용이 18개월마다 절반으로 줄었던 것처럼, AI 추론 비용도 비슷한 궤적을 따른다.

비용이 $0.001 수준이 되면, 추론이 사실상 "무료"가 된다. 이때 무슨 일이 벌어지는가?

**모든 소프트웨어에 AI 통합**: 현재는 "AI 기능 추가"가 비용 결정이지만, 추론이 무료면 기본 기능이 된다. 모든 앱이 챗봇, 추천, 개인화를 기본 제공한다.

**초개인화(Hyper-Personalization)**: 각 사용자마다 전용 AI 모델. 현재는 비용 때문에 불가능하지만, 추론이 무료면 가능하다. 당신만의 스타일, 선호도, 맥락을 완벽히 이해하는 AI.

**AI 에이전트의 폭발**: 추론 비용이 병목이 아니면, 수백 개의 에이전트가 백그라운드에서 작동한다. 하나는 이메일 분류, 하나는 뉴스 요약, 하나는 일정 최적화. "AI 비서"가 아니라 "AI 팀"이 된다.

하지만 이런 미래에도 병목은 남는다. **데이터 프라이버시**, **에너지 소비**, **인간 주의력**. AI가 무료로 무한 작업을 수행해도, 인간이 검토하고 결정하는 시간은 유한하다.

## FAQ

### Q1. GPT-5.2는 GPT-5와 별개 모델인가?

아니다. GPT-5.2는 GPT-5의 특화 버전이다. 동일한 기반 아키텍처를 사용하지만, ARC-AGI 같은 추론 작업에 최적화되었다. 일반 대화나 창의적 글쓰기에는 GPT-5가 더 나을 수 있다. 사용자는 ChatGPT에서 작업에 따라 모델을 선택할 수 있다. "GPT-5 (균형)", "GPT-5.2 (추론)", "GPT-5-Creative (창작)" 같은 옵션이 제공된다. API 사용자는 `model="gpt-5-reasoning"` 파라미터로 GPT-5.2를 호출한다. 가격은 동일하지만, 추론 작업에서 더 빠르고 정확하다.

### Q2. ARC-AGI 90%는 AGI 달성을 의미하는가?

아니다. François Chollet 본인도 "ARC-AGI는 AGI의 필요조건이지 충분조건이 아니다"라고 밝혔다. AGI는 모든 인지 작업에서 인간 수준 이상이어야 한다. ARC-AGI는 추상적 추론만 측정한다. 상식 추론(Winograd Schema), 사회적 지능(Theory of Mind), 창의성(Torrance Tests) 등 다른 측면은 평가하지 않는다. GPT-5.2는 격자 패턴은 잘 찾지만, "친구가 생일을 잊었다면 어떻게 반응해야 하나?" 같은 사회적 질문에는 여전히 약하다. AGI는 아직 멀었다.

### Q3. 비용 절감은 어떻게 달성했나? 성능 저하는 없나?

세 가지 방법으로 달성했다. (1) 모델 크기 축소: 5조 → 500억 파라미터, 추론 작업에는 작은 모델로 충분, (2) 조기 종료: 답을 찾으면 즉시 멈춤, 불필요한 탐색 제거, (3) 인프라 최적화: 커스텀 칩, 배치 처리, 캐싱. 성능 저하는 거의 없다. ARC-AGI-1에서 GPT-5(일반 버전)도 약 88%를 달성하는데, GPT-5.2는 90.3%로 오히려 높다. 이는 전문화(Specialization)의 이점이다. 범용 모델보다 특화 모델이 특정 작업에서 더 효율적이다. 다만, GPT-5.2는 다른 작업(예: 시 쓰기)에서는 GPT-5보다 못할 수 있다.

---

**출처:**
- [OpenAI Research - GPT-5.2 ARC-AGI Breakthrough](https://openai.com/research/gpt-5-2-arc-agi-breakthrough)
- [ARC-AGI Official Benchmark](https://arcprize.org/)
- [François Chollet - On the Measure of Intelligence (Paper)](https://arxiv.org/abs/1911.01547)
- [OpenAI Blog - Reasoning Cost Economics](https://openai.com/blog/reasoning-cost-economics-2026)
