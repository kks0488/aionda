---
title: 'ChitChats: 멀티모달 캐릭터 대화 지원'
slug: chitchats-multimodal-gpt-5-2-codex-streaming
date: '2026-01-22'
locale: ko
description: ChitChats은 이미지 입력과 실시간 스트리밍을 결합해 멀티모달 캐릭터 대화 경험을 강화하려는 시도를 보여줍니다.
tags:
  - llm
  - multimodal
  - chitchats
  - codex
  - ai-agent
author: AI온다
sourceId: '941686'
sourceUrl: 'https://gall.dcinside.com/mgallery/board/view/?id=thesingularity&no=941686'
verificationScore: 0.8166666666666668
alternateLocale: /en/posts/chitchats-multimodal-gpt-5-2-codex-streaming
coverImage: /images/posts/chitchats-multimodal-gpt-5-2-codex-streaming.png
---

## 세 줄 요약
- GPT-4o 등 최신 멀티모달 모델을 통해 대규모 이미지 데이터와 페이로드를 처리하며 시각적 정보를 대화에 결합한다.
- 토큰 단위 실시간 스트리밍 기술을 적용하여 응답 지연을 줄이고 사용자 경험을 개선한다.
- 오픈소스 레포지토리를 통해 로컬 런타임 구성과 에이전트 파라미터 조정이 가능해져 개발자 접근성이 높아졌다.

예: 사용자가 손으로 그린 옷 도안을 대화창에 보낸다. 캐릭터는 그림을 살피고 옷감의 느낌이나 색상 조화에 의견을 낸다. 창작 의도를 대화에 반영하며 이야기를 이어간다.

텍스트 중심의 캐릭터 대화 방식에 시각 정보를 결합하는 변화가 일어나고 있다. 인공지능(AI)은 사용자가 보낸 스크린샷의 분위기를 파악하거나 디자인 시안의 수정 사항을 제안한다. 텍스트와 이미지 등 서로 다른 형태의 데이터를 동시에 처리하는 멀티모달 환경이 캐릭터 인터랙션의 표준으로 자리 잡고 있다.

ChitChats 도구는 OpenAI Codex 환경에 이미지 인식 기능을 통합하여 캐릭터 대화의 몰입감을 높인다. 이번 기술 통합의 중점은 대규모 이미지 데이터 처리 능력과 토큰 단위의 실시간 스트리밍을 통한 반응 속도 최적화에 있다. 기존 텍스트 위주 에이전트가 가졌던 시각적 인지 한계를 해결하여 사용자는 입체적인 대화를 경험할 수 있다.

## 현황
OpenAI의 GPT-4o 등 최신 모델은 공식적으로 멀티모달 데이터 처리를 지원한다. 개발자는 API와 CLI를 통해 PNG 및 JPEG 형식의 이미지를 입력할 수 있다. 입력된 이미지는 단순한 첨부 파일을 넘어 프롬프트와 함께 컨텍스트로 분석된다. OpenAI의 멀티모달 API는 이미지당 최대 20MB의 용량을 지원하며, 요청당 이미지 입력 수는 모델의 컨텍스트 토큰 한도 내에서 유동적으로 처리됩니다.

비용 구조는 이미지 상세도에 따라 결정된다. 저해상도(low detail) 설정으로 전송하면 이미지당 85 토큰의 고정 비용이 발생한다. 고해상도 설정 시에는 이미지를 2048x2048 픽셀 이내로 조정한 뒤 타일 단위로 분할하여 처리하며, 소모되는 토큰량은 이미지의 해상도와 타일 수에 따라 가변적으로 결정된다. 명확한 토큰 계산 방식은 개발자가 멀티모달 에이전트 운영 비용을 정밀하게 예측하도록 돕는다.

ChitChats 도구는 Codex의 성능을 활용하기 위해 실시간 스트리밍 기술을 사용한다. 응답이 완성될 때까지 기다리지 않고 생성되는 토큰을 즉시 화면에 출력하는 방식이다. 이는 Claude Code 등 다른 도구와 비교했을 때 체감 지연 시간을 줄여주는 요소다. 현재 이 기술은 오픈소스 레포지토리로 배포되고 있으며, 사용자는 로컬 환경에서 직접 런타임을 구성하고 에이전트의 파라미터를 조정할 수 있다.

## 분석
캐릭터 대화에 시각 정보가 결합되는 것은 캐릭터의 페르소나를 강화하는 장치가 된다. 사용자가 공유한 사진이나 스크린샷을 캐릭터가 확인하고 대화에 반영할 때, 사용자는 AI가 상황을 이해하고 있다는 유대감을 느낀다. 특히 실시간 스트리밍 기술은 대화 흐름을 유지하여 기계적 지연으로 인한 몰입감 저해를 방지한다.

다만 기술적 한계와 검토할 점도 존재한다. 고해상도 이미지 처리는 토큰 비용이 커질 수 있어 대규모 대화 세션에서 운영 부담이 될 수 있다. 또한 ChitChats 도구가 Claude Code보다 빠른 반응 속도를 제공한다는 설명이 있으나, 구체적으로 단축된 시간을 증명하는 정량적 비교 데이터는 부족한 상태다. 실제 네트워크 환경이나 로컬 연산 자원에 따라 스트리밍 효율이 달라질 수 있음을 고려해야 한다.

페이로드/컨텍스트 한도는 고화질 이미지나 대량의 스크린샷을 동시에 처리해야 하는 전문적인 디자인 협업 시나리오에서 병목 현상을 일으킬 수 있다. 멀티모달 에이전트가 실질적인 조력자가 되기 위해서는 시각 정보 처리 속도뿐만 아니라, 이미지 내의 복잡한 텍스트나 레이아웃을 계층적으로 이해하는지에 대한 검증이 추가로 필요하다.

## 실전 적용
개발자와 사용자는 텍스트 명령에서 벗어나 시각적 자산을 활용할 수 있다. ChitChats의 오픈소스 구조를 활용하면 로컬 런타임을 구축해 개인화된 멀티모달 캐릭터를 제작할 수 있다. 웹 퍼블리셔라면 코딩 중 발생한 레이아웃 오류 스크린샷을 Codex CLI에 입력하여 수정 제안을 받을 수 있다.

**오늘 바로 할 일:**
- OpenAI API 대시보드에서 멀티모달 모델의 접근 권한과 토큰 사용량을 확인한다.
- ChitChats 오픈소스 레포지토리를 복제하여 로컬 환경에 런타임을 설치하고 이미지 입력 기능을 시험한다.
- 캐릭터 에이전트의 시스템 프롬프트에 이미지 분석 결과를 대화에 활용하도록 지침을 추가하여 반응의 일관성을 점검한다.

## FAQ
**Q: Codex API가 지원하는 이미지 파일 형식과 크기 제한은 무엇인가?**
A: 지원되는 이미지 형식과 용량 제한은 사용하는 API 문서의 최신 가이드를 따르는 것이 안전합니다. 일반적으로는 PNG와 JPEG 같은 표준 포맷을 지원하며, 요청 크기 제한은 모델과 엔드포인트에 따라 달라질 수 있습니다.

**Q: 고해상도 이미지 입력 시 토큰 비용은 어떻게 계산되는가?**
A: 저해상도 설정 시에는 이미지당 85 토큰이 소모됩니다. 고해상도 설정에서는 이미지가 2048x2048 픽셀 이내로 조정된 뒤 타일 단위로 처리되며, 토큰 비용은 이미지의 해상도와 타일 수에 따라 가변적으로 증가합니다.

**Q: Claude Code와 비교했을 때 ChitChats의 스트리밍 기술은 어떤 이점이 있는가?**
A: 토큰 단위 실시간 스트리밍을 통해 응답 전체를 기다릴 필요 없이 텍스트와 시각적 피드백을 즉시 확인할 수 있어 대화의 연속성 측면에서 유리합니다. 다만 구체적인 속도 차이는 사용 환경에 따라 다를 수 있습니다.

## 결론
OpenAI Codex와 ChitChats의 결합은 캐릭터 대화를 시각 정보 영역으로 확장했다. 실시간 스트리밍 기술은 멀티모달 인터랙션의 체감 품질을 끌어올릴 수 있는 요소다. 향후 과제는 이러한 기술이 실제 사용자 경험에서 얼마나 정밀한 시각적 이해도를 보여주는지, 그리고 토큰 비용을 상쇄할 만큼의 가치를 창출하는지 여부다. 캐릭터와의 대화는 이제 읽는 단계를 넘어 보는 단계로 진입했다.
---

## 참고 자료

- 🛡️ [Images and vision | OpenAI API](https://openai.com/index/images-and-vision-api)
- 🛡️ [Codex CLI features - OpenAI for developers](https://openai.com/index/codex-cli-features)
