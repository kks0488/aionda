---
title: 'AI 협업의 시대, Humans&의 조정 특화 모델'
slug: humans-and-ai-coordination-foundation-model
date: '2026-01-22'
locale: ko
description: Humans&가 단순 대화를 넘어 AI 간 협업과 조정을 위한 새로운 파운데이션 모델과 평가 지표를 통해 산업의 변화를 주도합니다.
tags:
  - llm
  - multi-agent
  - collaboration
  - foundation-model
author: AI온다
sourceId: techcrunch-ai-63a752l
sourceUrl: >-
  https://techcrunch.com/2026/01/22/humans-thinks-coordination-is-the-next-frontier-for-ai-and-theyre-building-a-model-to-prove-it/
verificationScore: 0.8166666666666668
coverImage: /images/posts/humans-and-ai-coordination-foundation-model.png
---

예: 여러 개의 인공지능 에이전트가 복잡한 공급망 관리 과정에서 서로 자원을 배분하고 우선순위를 협상한다. 인간 관리자가 개입하지 않아도 각 에이전트는 전체 시스템의 효율성을 극대화하기 위한 최적의 합의점을 스스로 찾아낸다. 이 과정에서 발생하는 수만 가지 변수와 충돌은 실시간으로 조정되며 하나의 유기체처럼 작동한다.

챗봇에게 질문을 던지고 답변을 기다리는 시대가 저물고 있습니다. 이제 AI의 다음 전장은 단순한 대화 능력이 아니라, 복잡한 환경에서 인간 및 다른 AI와 협력하여 목표를 달성하는 '조정(Coordination)' 능력입니다. 메타(Meta), xAI 등 주요 테크 기업 출신 엔지니어들이 설립한 스타트업 'Humans&'가 대화가 아닌 협업에 특화된 새로운 파운데이션 모델을 통해 이 변화를 주도하고 있습니다.

## TL;DR
- Humans&는 대화 중심의 기존 모델에서 벗어나 AI 간 및 인간과의 복잡한 협업을 목적으로 하는 파운데이션 모델을 개발 중입니다.
- AI 성능 측정 기준이 단순 벤치마크에서 실시간 목표 추론과 관계 증진 능력을 평가하는 'ColorGrid' 및 'HumaneBench'로 이동하고 있습니다.
- 장기 강화학습(Long-horizon RL)과 다중 에이전트 시스템을 결합해 협업 특화 모델의 새로운 표준 설정을 목표로 합니다.

## 현황: 채팅을 넘어 조정의 영역으로
Humans&는 앤스로픽(Anthropic), 오픈AI(OpenAI), 구글 딥마인드(Google DeepMind) 등 주요 테크 기업 출신 엔지니어들이 의기투합해 설립한 기업입니다. 이들은 기존 언어 모델이 가진 한계를 명확히 지적합니다. 현재의 LLM은 텍스트를 생성하고 정보를 요약하는 데는 능숙하지만, 여러 주체가 얽힌 복잡한 프로젝트를 조율하거나 장기적인 목표를 위해 전략적으로 행동하는 능력은 여전히 부족하기 때문입니다.

업계에서는 이러한 협업 능력을 평가하기 위한 새로운 잣대를 도입하고 있습니다. 2025년 1월에 등장한 'ColorGrid'는 실시간으로 타자의 의도를 추론하고 지원하는 인간-AI 협업 능력을 측정하는 벤치마크입니다. 또한, Humans&가 제시한 'HumaneBench'는 인간의 웰빙과 관계 증진 등을 핵심 원칙으로 삼아 모델의 사회적 조정 능력을 평가합니다. Humans&는 이러한 지표를 바탕으로 단순한 '비서'를 넘어선 '파트너'로서의 AI를 구축하고 있습니다.

Humans&의 첫 번째 상업용 제품과 구체적인 성능 수치는 2026년 하반기 출시 이후에나 확인할 수 있을 것으로 보입니다. 현재 이들은 장기 강화학습 기술을 적용해, 모델이 수천 단계 이상의 추론 과정을 거쳐야 하는 복잡한 업무에서도 일관된 성능을 유지하도록 훈련하는 데 집중하고 있습니다.

## 분석: 왜 지금 '조정'인가?
지금까지의 AI 산업은 모델의 크기를 키우고 더 많은 데이터를 학습시키는 '스케일링 법칙'에 의존해 왔습니다. 하지만 단순한 정보의 양이 지능의 질을 보장하지 않는다는 사실이 드러나고 있습니다. 기업 환경에서 필요한 것은 질문에 답하는 AI가 아니라, 다른 팀의 에이전트와 일정 부딪힘 없이 협상하고 프로젝트의 마감 기한을 준수하며 자원을 효율적으로 배분하는 '조정자'입니다.

하지만 기술적 난관은 여전합니다. 다중 에이전트 시스템에서 발생할 수 있는 '목표 이탈(Goal Drift)'이나 에이전트 간의 통신 과부하 문제는 해결해야 할 숙제입니다. 특히 인간의 모호한 의도를 AI가 정확히 파악하여 협업에 반영하는 과정에서 발생할 수 있는 윤리적, 안전성 문제도 무시할 수 없습니다. Humans&가 장기 강화학습과 함께 인간의 가치를 중심에 둔 'HumaneBench' 등의 평가 지표를 중요하게 다루는 이유도 바로 여기에 있습니다.

## 실전 적용: 협업 AI 시대를 준비하는 방법
개발자와 기업 운영자는 이제 단일 모델의 성능보다 여러 모델이 유기적으로 연결되는 '생태계'의 관점에서 접근해야 합니다. 개별 업무를 수행하는 에이전트들이 어떻게 정보를 교환하고 충돌을 해결할지 설계하는 능력이 핵심 경쟁력이 될 것입니다.

예: 대규모 소프트웨어 개발 프로젝트에서 코딩 에이전트, 테스트 에이전트, 문서화 에이전트가 서로의 진행 상황을 실시간으로 확인하며 일정을 조정하는 시나리오를 구성해 볼 수 있습니다. 이 과정에서 각 에이전트는 자신의 작업이 전체 일정에 미치는 영향을 계산하여 작업 순서를 스스로 변경합니다.

**오늘 바로 할 일 체크리스트:**
- 현재 조직 내에서 AI가 단독으로 수행하는 업무와 협업이 필요한 업무를 분리하여 리스트를 작성하십시오.
- ColorGrid나 HumaneBench와 같은 최신 협업 관련 벤치마크 데이터를 확인하여 차세대 AI의 평가 기준을 파악하십시오.
- 다중 에이전트 워크플로우를 테스트할 수 있는 샌드박스 환경 구축을 검토하십시오.

## FAQ
**Q: 기존의 대화형 모델(ChatGPT 등)과 Humans& 모델의 가장 큰 차이점은 무엇인가요?**
A: 기존 모델은 사용자의 입력에 대해 최적의 답변을 생성하는 데 집중합니다. 반면 Humans&의 모델은 다수의 참여자(인간 혹은 다른 AI) 사이에서 목표를 공유하고, 갈등을 조정하며, 최종 목적지에 도달하기 위한 전략적 행동을 취하도록 설계되었습니다.

**Q: Humans&의 모델을 지금 바로 사용할 수 있나요?**
A: 현재는 개발 단계에 있으며, 구체적인 제품 및 성능 지표는 2026년 하반기 출시 이후에 확인할 수 있을 것으로 예상됩니다. 현재는 공개된 벤치마크 지표 등을 통해 그 방향성만 확인할 수 있는 상태입니다.

**Q: AI 간의 조정이 활발해지면 인간의 통제권을 잃게 될 우려는 없나요?**
A: 그것이 바로 HumaneBench와 같은 평가 지표가 중요한 이유입니다. Humans&는 인간의 웰빙과 관계 증진을 핵심 원칙으로 삼아, AI 간의 조정 과정이 항상 인간의 가치 범주 안에서 이루어지도록 설계하고 있습니다.

## 결론
AI 기술의 무게중심은 이제 '무엇을 아는가'에서 '어떻게 함께 일하는가'로 이동하고 있습니다. Humans&의 시도는 대화형 AI가 가진 태생적 한계를 극복하고, 실제 산업 현장에서 복잡한 조정 업무를 수행할 수 있는 파운데이션 모델의 탄생을 예고합니다. 2026년 하반기, 이들이 제시할 새로운 표준이 AI 에이전트 생태계를 어떻게 재편할지 주시해야 합니다.
---

## 참고 자료

- 🛡️ [Source](https://techcrunch.com/2026/01/22/humans-thinks-coordination-is-the-next-frontier-for-ai-and-theyre-building-a-model-to-prove-it/)
- 🏛️ [ColorGrid: A Multi-Agent Non-Stationary Environment for Goal Inference and Assistance](https://arxiv.org/abs/2501.05789)
