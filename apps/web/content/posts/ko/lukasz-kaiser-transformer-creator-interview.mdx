---
title: '우카시 카이저: 트랜스포머 설계자의 솔직한 고백'
slug: lukasz-kaiser-transformer-creator-interview
date: '2026.01.10 16:20:00'
locale: ko
description: >-
  트랜스포머 아키텍처 공동 창시자 우카시 카이저가 AI 개발의 진짜 병목, OpenAI 인프라의 현실, 그리고 AGI로 가는 길에 대한 솔직한
  인사이트를 팟캐스트 인터뷰에서 공개했습니다.
tags:
  - interview
  - openai
author: AI온다
sourceId: '930168'
sourceUrl: 'https://gall.dcinside.com/mgallery/board/view/?id=thesingularity&no=930168'
verificationScore: 0.9
alternateLocale: /en/posts/lukasz-kaiser-transformer-creator-interview
coverImage: /images/posts/lukasz-kaiser-transformer-creator-interview.jpeg
---

우카시 카이저(Lukasz Kaiser)는 2017년 트랜스포머 아키텍처를 소개한 전설적인 논문 "Attention is All You Need"의 8명 저자 중 한 명입니다. 현재 OpenAI에서 활동 중인 그가 최근 Dwarkesh 팟캐스트에 출연해 AI 연구의 현주소를 논하며 개발 병목, 인프라 한계, 그리고 범용 인공지능으로 가는 길에 대한 놀라운 진실을 공개했습니다.

## 핵심 인사이트

### 1. 진짜 병목은 아이디어가 아니라 검증이다

카이저는 획기적인 아이디어가 AI 발전의 제한 요소라는 일반적인 가정에 이의를 제기합니다. 실제 제약은 아이디어가 작동하는지 구현과 실행을 통해 검증하는 능력이라고 주장합니다.

"아이디어는 충분합니다. 병목은 그것들을 코딩하고 실험을 돌려서 실제로 작동하는지 확인하는 것입니다."

이는 OpenAI 연구자들이 Codex 같은 도구에 크게 의존하는 이유를 설명합니다. 경쟁은 새로운 접근법을 생각해내는 것이 아니라 가설을 대규모로 빠르게 테스트하는 것입니다.

### 2. GPU와 에너지가 궁극적 제약이다

코딩 속도를 넘어, 카이저는 두 가지 근본적인 물리적 한계를 지적합니다: 컴퓨팅 파워와 에너지 소비. 모델이 지수적으로 확장되면서 훈련에 필요한 인프라가 주요 제약 요소가 됩니다.

"우리는 점점 더 GPU와 에너지에 제약받고 있습니다. 코드를 아무리 최적화해도 결국 하드웨어 한계에 부딪힙니다."

이러한 현실이 업계의 맞춤형 AI 칩과 데이터 센터 인프라에 대한 막대한 투자를 주도합니다.

### 3. 내부에서는 계단, 외부에서는 폭발로 보인다

카이저는 AI 진보가 관점에 따라 어떻게 다르게 보이는지에 대한 흥미로운 시각을 제공합니다. 점진적 개선을 매일 연구하는 연구자들에게 발전은 단계적으로 느껴집니다. 하지만 외부 관찰자들에게는 이러한 누적된 개선이 갑작스러운 능력 도약으로 나타납니다.

"내부적으로는 꾸준한 진전이 보입니다. 외부에서는 갑작스러운 돌파구처럼 보입니다. 두 관점 모두 사실입니다."

이는 AI 시스템이 명시적으로 훈련받지 않은 새로운 능력으로 갑자기 "깨어나는" 것처럼 보이는 반복적인 패턴을 설명합니다.

### 4. "우리 소프트웨어는 사실 꽤 별로다" - 업계의 고백

신선한 솔직함의 순간에, 카이저는 구글과 OpenAI 모두 소프트웨어 인프라 품질로 고군분투하고 있다고 인정합니다. 세계적 수준의 엔지니어들이 있음에도 불구하고, AI 개발의 빠른 속도가 기술적 부채와 차선책 시스템으로 이어졌습니다.

"내부 도구와 인프라를 보면, 솔직히 그렇게 좋지 않습니다. 우리는 모든 것을 제대로 구축하기에는 너무 빠르게 움직이고 있습니다."

이 고백은 최첨단 AI 연구소에서 연구 속도와 엔지니어링 엄격성 사이의 긴장을 강조합니다.

### 5. 추론 모델은 초기 단계이며 엄청난 잠재력이 있다

OpenAI의 o1 같은 시스템에 관해, 카이저는 추론 강화 모델이 아직 초기 단계에 있다고 강조합니다. 현재 구현은 모델이 확장된 사고 연쇄 처리에 참여할 수 있을 때 가능한 것의 시작에 불과합니다.

"추론 모델로 우리가 지금 가진 것은 극히 초보적입니다. 개선의 여지가 엄청납니다."

이는 다음 세대 추론 시스템이 훨씬 더 정교한 문제 해결 능력을 보여줄 수 있음을 시사합니다.

### 6. 비디오 학습은 월드 모델을 구축한다

카이저는 AI 훈련을 위한 비디오 데이터의 중요성, 특히 강건한 월드 모델 개발에 대해 논의합니다. 정적 이미지나 텍스트와 달리, 비디오는 객체가 어떻게 상호작용하고 물리 법칙이 작동하는지에 대한 시간적 정보를 제공합니다.

"비디오에서 학습하면 모델이 정적 데이터로는 포착할 수 없는 방식으로 인과관계와 물리학을 이해하는 데 도움이 됩니다."

이는 업계의 최근 비디오 생성 모델과 멀티모달 훈련 접근법에 대한 집중을 설명합니다.

### 7. 샘 알트만의 리더십 스타일

OpenAI CEO에 대해 질문을 받았을 때, 카이저는 알트만이 단기적 과제를 헤쳐나가면서 장기적 목표에 집중을 유지하는 능력을 칭찬합니다. 그는 알트만을 연구팀을 방해 요소로부터 효과적으로 보호하고 AGI에 대한 지속적인 작업을 가능하게 하는 사람으로 묘사합니다.

"샘은 조직이 중요한 것에 집중하도록 유지하는 데 매우 뛰어납니다. 그는 잡음을 처리해서 우리가 연구에 집중할 수 있게 합니다."

## AGI에 대한 견해

카이저는 범용 인공지능 도달에 대해 신중한 낙관론을 표현합니다. 그는 구체적인 일정 예측을 피하지만, 알고리즘 개선과 결합된 현재의 스케일링 접근법이 타당하게 AGI 수준 시스템으로 이어질 수 있다고 제안합니다.

"우리에게 길이 있다고 생각합니다. 5년이 걸릴지 15년이 걸릴지는 확실하지 않지만, 근본적인 접근법은 타당해 보입니다."

그는 AGI가 단일한 극적인 순간으로 도착하지 않고, 좁은 AI 시스템이 점진적으로 더 범용 목적이 되어온 것처럼, 다양한 영역에 걸친 능력의 점진적 확장으로 올 것이라고 강조합니다.

## 결론

우카시 카이저의 인터뷰는 최첨단 AI 연구의 운영 현실에 대한 드문 통찰을 제공합니다. 병목은 뛰어난 통찰보다는 검증 속도, 컴퓨팅 자원, 그리고 엔지니어링 인프라에 더 관련되어 있습니다. 업계 과제에 대한 그의 솔직한 평가는, AGI에 대한 신중한 낙관론과 결합되어, 과대 광고와 회의론 모두를 뚫는 근거 있는 관점을 제공합니다.

AI 진보를 추적하는 사람들에게, 카이저의 인사이트는 추론 시스템, 멀티모달 학습, 그리고 컴퓨팅 효율성의 개선을 지켜보는 것이 갑작스러운 패러다임 전환을 기다리는 것보다 더 유익할 수 있음을 시사합니다.

---

*이 요약은 트랜스포머 아키텍처, AI 개발, 그리고 AGI로 가는 길에 대해 논의한 Dwarkesh 팟캐스트에서의 우카시 카이저 출연을 기반으로 합니다.*
