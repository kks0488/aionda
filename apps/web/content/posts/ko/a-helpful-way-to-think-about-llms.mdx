---
title: "거대언어모델을 확장된 무의식으로 통합하고 엄격한 자기 검증을 통해 완성하라"
slug: "a-helpful-way-to-think-about-llms"
date: "2026.01.10 04:11:56"
locale: "ko"
description: "거대언어모델(LLM)은 외부의 지식 창고가 아니다. 당신의 무의식적 사고를 확장하는 도구다. LLM을 타자화하지 말고 당신의 일부로 받아들여야 한다. 인간의 생각은 발생과 검증의 단계를 거친다. 아이디어가 떠오르는 것은 통제 불가능한 영역이다. LLM은 이 '떠올리는' 과정을 가속하는 "
tags: ["opinion"]
author: "Singularity Blog"
sourceId: "929863"
sourceUrl: "https://gall.dcinside.com/mgallery/board/view/?id=thesingularity&no=929863"
verificationScore: 0.57
alternateLocale: "/en/posts/a-helpful-way-to-think-about-llms"
coverImage: "/images/posts/a-helpful-way-to-think-about-llms.jpeg"
---

거대언어모델(LLM)은 외부의 지식 창고가 아니다. 당신의 무의식적 사고를 확장하는 도구다. LLM을 타자화하지 말고 당신의 일부로 받아들여야 한다.

## 사고의 두 단계
인간의 생각은 발생과 검증의 단계를 거친다. 아이디어가 떠오르는 것은 통제 불가능한 영역이다. LLM은 이 '떠올리는' 과정을 가속하는 외부 엔진이다. 사고의 범위를 넓히는 자극제로 활용해야 한다.

## AI의 출력을 나의 생각으로 보기
LLM의 답변을 '진리'로 받들지 마라. 그것이 방금 당신이 떠올린 아이디어라고 가정하라. AI의 반박은 당신의 자기의심이고, 칭찬은 당신의 자기만족이다. 주관성을 유지할 때 비로소 LLM의 도구성이 명확해진다.

## 확률적 지식의 한계
LLM은 인터넷 데이터를 확률 분포로 학습한 결과물이다. 원본 데이터를 그대로 복사한 백과사전이 아니다. [확률적 앵무새(Stochastic Parrots)](https://dl.acm.org/doi/10.1145/3442188.3445922) 논문이 지적하듯, 학습 데이터 자체가 불완전하다. 모든 출력값은 엄격한 자기검증의 대상이다.

## 데이터 규모의 차이
물론 LLM은 개인보다 압도적으로 많은 정보를 안다. 강화학습(RLHF)을 통해 인간의 선호도를 학습하기도 했다. 하지만 정보의 양이 곧 신뢰성을 의미하지는 않는다.

## 인지 루프의 완성
LLM을 당신의 확장된 무의식으로 정의하라. 더 많은 자극을 받고, 더 치열하게 검증하라. 그것이 AI 시대에 인간이 사고하는 방식이다.

---
* [Stochastic Parrots (Bentley University)](https://dl.acm.org/doi/10.1145/3442188.3445922)
* [Thinking, Fast and Slow (Daniel Kahneman)](https://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374533555)
* [LLMs as an extension of mind (Simon Willison)](https://simonwillison.net/)
